{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khAinpqS2e2S",
        "outputId": "375737ec-efbd-40b0-b283-82b150fca62a"
      },
      "outputs": [],
      "source": [
        "# !pip install kagglehub\n",
        "# !pip install pandas\n",
        "# !pip install nltk\n",
        "# !pip install scikit-learn\n",
        "# !pip install tensorflow\n",
        "# !pip install matplotlib\n",
        "# !pip install seaborn\n",
        "# !pip install torch\n",
        "# !pip install transformers\n",
        "# !pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vrFm_hUc2e2W"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Code\\Data Science\\Projects\\brazilian-e-commerce-nlp-deep-learning\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForSequenceClassification,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALRsADqg2e2Y"
      },
      "source": [
        "\n",
        "\n",
        "olist_customers_dataset.csv\n",
        "olist_geolocation_dataset.csv\n",
        "olist_orders_dataset.csv\n",
        "olist_order_items_dataset.csv\n",
        "olist_order_payments_dataset.csv\n",
        "olist_order_reviews_dataset.csv\n",
        "olist_products_dataset.csv\n",
        "olist_sellers_dataset.csv\n",
        "product_category_name_translation.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6YFwdkk2e2Z"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use the [Brazilian E-Commerce](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce) dataset, which contains reviews from products bought in e-commerces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQhAn17h2e2Z",
        "outputId": "6eeedf27-40ae-4ac9-c5d3-e6d1b7e218be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.11).\n",
            "Path to dataset files: C:\\Users\\darth\\.cache\\kagglehub\\datasets\\olistbr\\brazilian-ecommerce\\versions\\2\n"
          ]
        }
      ],
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"olistbr/brazilian-ecommerce\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mUmuSvIW2e2a"
      },
      "outputs": [],
      "source": [
        "# Reading all the files\n",
        "# olist_customer = pd.read_csv(path + 'olist_customers_dataset.csv')\n",
        "# olist_geolocation = pd.read_csv(path + 'olist_geolocation_dataset.csv')\n",
        "# olist_orders = pd.read_csv(path + 'olist_orders_dataset.csv')\n",
        "# olist_order_items = pd.read_csv(path + 'olist_order_items_dataset.csv')\n",
        "# olist_order_payments = pd.read_csv(path + 'olist_order_payments_dataset.csv')\n",
        "olist_order_reviews = pd.read_csv(path + '//olist_order_reviews_dataset.csv')\n",
        "# olist_products = pd.read_csv(path + 'olist_products_dataset.csv')\n",
        "# olist_sellers = pd.read_csv(path + 'olist_sellers_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Ft2GFMdD2e2b",
        "outputId": "922b95ba-3378-4287-8975-f114cde36069"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>99224.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.086421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.347579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       review_score\n",
              "count  99224.000000\n",
              "mean       4.086421\n",
              "std        1.347579\n",
              "min        1.000000\n",
              "25%        4.000000\n",
              "50%        5.000000\n",
              "75%        5.000000\n",
              "max        5.000000"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "olist_order_reviews.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "mnrdQZrK2e2b",
        "outputId": "88964732-d970-4e05-d6c0-152a67918116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (40977, 2)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>Recebi bem antes do prazo estipulado.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>Parab√©ns lojas lannister adorei comprar pela I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Vendedor confi√°vel, produto ok e entrega antes...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   score                                            comment\n",
              "0      5              Recebi bem antes do prazo estipulado.\n",
              "1      5  Parab√©ns lojas lannister adorei comprar pela I...\n",
              "2      4  aparelho eficiente. no site a marca do aparelh...\n",
              "3      4    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n\n",
              "4      5  Vendedor confi√°vel, produto ok e entrega antes..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_comments = olist_order_reviews.loc[:, ['review_score', 'review_comment_message']]\n",
        "df_comments = df_comments.dropna(subset=['review_comment_message'])\n",
        "df_comments = df_comments.reset_index(drop=True)\n",
        "\n",
        "print(f'Dataset shape: {df_comments.shape}')\n",
        "df_comments.columns = ['score', 'comment']\n",
        "df_comments.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzukufS62e2c"
      },
      "source": [
        "We will consider a binary classification problem, with negative comments being with score below 4 and good reviews being 4 and 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls4hqbJp2e2c",
        "outputId": "f2de4453-4256-491a-c7c8-30619d9fc00e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "40977"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = df_comments['score']\n",
        "y = y.apply(lambda x: 0 if x < 4 else 1)\n",
        "\n",
        "len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "DMUW1FgP2e2d",
        "outputId": "bfdfbf81-f37b-407e-9609-ae6992f432ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "score\n",
              "1    26530\n",
              "0    14447\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.value_counts(sort=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Leu95p52e2e"
      },
      "source": [
        "We have almost 41k comments that could be used for training a sentimental analysis model. But, beforehand we have to do some preprocessing on the text to transform the comment input into a vector that can be interpreted for a Machine Learning model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_0RZMgi2e2e"
      },
      "source": [
        "## Natural language processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri09aDIL2e2e"
      },
      "source": [
        "### Regular expressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0xqUjBg2e2e"
      },
      "source": [
        "First lest's define a function to help visualize transformations on data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_Y83EHtQ2e2f"
      },
      "outputs": [],
      "source": [
        "def print_diff(dataset_original, dataset_changed, limit=4):\n",
        "    # Print the original and changed values from lists\n",
        "    count = 0\n",
        "    for original, modified in zip(dataset_original, dataset_changed):\n",
        "        if original != modified:\n",
        "            print(f'Original: {original}')\n",
        "            print(f'Changed:  {modified}')\n",
        "            print('')\n",
        "            count += 1\n",
        "            if count >= limit:\n",
        "                break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuRcNIUe2e2f"
      },
      "source": [
        "##### \\n and \\r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWrE_R6E2e2f"
      },
      "source": [
        "As long as we consider the global internet as the source of our comments, probably we have to deal with some HTML tags, break lines, special characteres and other content that could be part of the dataset. Let's dig a little bit more on Regular Expressions to search for those patterns.\n",
        "\n",
        "First of all, let's define a function that will be used for analysing the results of an applied regular expression. With this we can validate our text pre processing in an easier way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAr5oCeT2e2g",
        "outputId": "2183de62-af26-4ebb-f14d-b260dc4e62a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: Mas um pouco ,travando...pelo valor ta Boa.\n",
            "\n",
            "Changed:  Mas um pouco ,travando...pelo valor ta Boa.  \n",
            "\n",
            "Original: A compra foi realizada facilmente.\n",
            "A entrega foi efetuada muito antes do prazo dado.\n",
            "O produto j√° come√ßou a ser usado e at√© o presente,\n",
            "sem problemas.\n",
            "Changed:  A compra foi realizada facilmente.  A entrega foi efetuada muito antes do prazo dado.  O produto j√° come√ßou a ser usado e at√© o presente,  sem problemas.\n",
            "\n",
            "Original: recebi somente 1 controle Midea Split ESTILO.\n",
            "Faltou Controle Remoto para Ar Condicionado Consul\n",
            "Changed:  recebi somente 1 controle Midea Split ESTILO.  Faltou Controle Remoto para Ar Condicionado Consul\n",
            "\n",
            "Original: Ocorreu tudo como contratado sendo a entrega realizada antes do prazo \n",
            " Estou satisfeita\n",
            "\n",
            "Changed:  Ocorreu tudo como contratado sendo a entrega realizada antes do prazo    Estou satisfeita  \n",
            "\n"
          ]
        }
      ],
      "source": [
        "def re_breakline(text_list):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text_list: list object with text content to be prepared [type: list]\n",
        "    \"\"\"\n",
        "\n",
        "    # Applying regex\n",
        "    return [re.sub('[\\n\\r]', ' ', r) for r in text_list]\n",
        "\n",
        "# Creating a list of comment reviews\n",
        "reviews = list(df_comments['comment'].values)\n",
        "\n",
        "# Applying RegEx\n",
        "reviews_breakline = re_breakline(reviews)\n",
        "df_comments['re_breakline'] = reviews_breakline\n",
        "\n",
        "# Verifying results\n",
        "print_diff(reviews, reviews_breakline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Word substitution\n",
        "\n",
        "We will substitute some metadata for a word representing the concept. The main idea is to generalize the concept, making it easier for the model to get more information from this data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTrs1rQt2e2g"
      },
      "source": [
        "##### links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLdPtI6b2e2g",
        "outputId": "3f36f3bb-5d99-4908-a103-82790e588448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: comprei o produto pela cor ilustrada pelo site da loja americana, no site mostra ser preto http://prntscr.com/jkx7hr quando o produto chegou aqui veio todos com a mesma cor, tabaco http://prntscr.com/\n",
            "Changed:  comprei o produto pela cor ilustrada pelo site da loja americana, no site mostra ser preto  link  quando o produto chegou aqui veio todos com a mesma cor, tabaco  link \n",
            "\n"
          ]
        }
      ],
      "source": [
        "def re_hiperlinks(text_list):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text_list: list object with text content to be prepared [type: list]\n",
        "    \"\"\"\n",
        "\n",
        "    # Applying regex\n",
        "    pattern = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
        "    return [re.sub(pattern, ' link ', r) for r in text_list]\n",
        "\n",
        "# Applying RegEx\n",
        "reviews_hiperlinks = re_hiperlinks(reviews_breakline)\n",
        "df_comments['re_hiperlinks'] = reviews_hiperlinks\n",
        "\n",
        "# Printing differences\n",
        "print_diff(reviews_breakline, reviews_hiperlinks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx4Da0j22e2h"
      },
      "source": [
        "##### dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiX7V5Jx2e2h",
        "outputId": "e1a59983-ad76-4678-e20c-f73ece627f53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: A targaryen n√£o √© de confian√ßa n√£o entregou a minha compra e colocou no rastreamento do pedido que foi entregue no dia 14/12/17 empresa falsa quero receber meus produtos que foram pagos com boleto bancari\n",
            "Changed:  A targaryen n√£o √© de confian√ßa n√£o entregou a minha compra e colocou no rastreamento do pedido que foi entregue no dia  data  empresa falsa quero receber meus produtos que foram pagos com boleto bancari\n",
            "\n",
            "Original: ENTREGA MUITO DEMORADA, COMPREI EM 26/03/2018 E AT√â AGORA N√ÉO RECEBI OS PRODUTOS\n",
            "Changed:  ENTREGA MUITO DEMORADA, COMPREI EM  data  E AT√â AGORA N√ÉO RECEBI OS PRODUTOS\n",
            "\n",
            "Original: ainda nao recebi e a ultima informacao sobre p produto e do dia 08/12/2017.\n",
            "Changed:  ainda nao recebi e a ultima informacao sobre p produto e do dia  data .\n",
            "\n",
            "Original: Comprei duas bonecas baby kiss Sid nil dia 07/12/17 e eles entregaram somente 1 boneca ,n√£o veio junto nota fiscal,caixa amassada e tamb√©m n√£o consigo contato com a lannister o telefone s√≥ da ocupado\n",
            "Changed:  Comprei duas bonecas baby kiss Sid nil dia  data  e eles entregaram somente 1 boneca ,n√£o veio junto nota fiscal,caixa amassada e tamb√©m n√£o consigo contato com a lannister o telefone s√≥ da ocupado\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def re_dates(text_list):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text_list: list object with text content to be prepared [type: list]\n",
        "    \"\"\"\n",
        "\n",
        "    # Applying regex\n",
        "    pattern = '([0-2][0-9]|(3)[0-1])(\\/|\\.)(((0)[0-9])|((1)[0-2]))(\\/|\\.)\\d{2,4}'\n",
        "    return [re.sub(pattern, ' data ', r) for r in text_list]\n",
        "\n",
        "\n",
        "# Applying RegEx\n",
        "reviews_dates = re_dates(reviews_hiperlinks)\n",
        "df_comments['re_dates'] = reviews_dates\n",
        "\n",
        "# Verifying results\n",
        "print_diff(reviews_hiperlinks, reviews_dates)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atie-uYj2e2h"
      },
      "source": [
        "##### money"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP2RbQS22e2i",
        "outputId": "e46539ea-e70b-41e0-c0c5-6ac0058c0b84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: Este foi o pedido  Balde Com 128 Pe√ßas - Blocos De Montar 2 un - R$ 25,00 cada (N√ÉO FOI ENTREGUE)  Vendido e entregue targaryen  Tapete de Eva N¬∫ Letras 36 Pe√ßas Crian√ßas 1 un - R$ 35,90 (ESTE FOI ENTREG\n",
            "Changed:  Este foi o pedido  Balde Com 128 Pe√ßas - Blocos De Montar 2 un -  dinheiro  cada (N√ÉO FOI ENTREGUE)  Vendido e entregue targaryen  Tapete de Eva N¬∫ Letras 36 Pe√ßas Crian√ßas 1 un -  dinheiro  (ESTE FOI ENTREG\n",
            "\n",
            "Original: Comprei 4 produtos, sendo que s√≥ recebi 3. Faltou um len√ßol branco sem el√°stico. Foi quase R$ 100,00. E como eu fico? No prejuizo?\n",
            "Changed:  Comprei 4 produtos, sendo que s√≥ recebi 3. Faltou um len√ßol branco sem el√°stico. Foi quase  dinheiro . E como eu fico? No prejuizo?\n",
            "\n",
            "Original: Rel√≥gio bel√≠ssimo, muito elegante, inacredit√°vel diante do valor de menos de R$ 150,00! Veio muito bem embrulhado e protegido, fora que tem tamb√©m caixa muito chique, como se fosse j√≥ia!!! Recomendo\n",
            "Changed:  Rel√≥gio bel√≠ssimo, muito elegante, inacredit√°vel diante do valor de menos de  dinheiro ! Veio muito bem embrulhado e protegido, fora que tem tamb√©m caixa muito chique, como se fosse j√≥ia!!! Recomendo\n",
            "\n",
            "Original: Entrega super r√°pida. Quanto ao produto, n√£o gostei tanto, imaginei que seria melhor e mais bonito, se tivesse visto em uma loja, pegado em m√£os antes n√£o teria pagado R$21,90 n√£o, mas ok.\n",
            "Changed:  Entrega super r√°pida. Quanto ao produto, n√£o gostei tanto, imaginei que seria melhor e mais bonito, se tivesse visto em uma loja, pegado em m√£os antes n√£o teria pagado  dinheiro  n√£o, mas ok.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def re_money(text_list):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text_list: list object with text content to be prepared [type: list]\n",
        "    \"\"\"\n",
        "\n",
        "    # Applying regex\n",
        "    pattern = '[R]{0,1}\\$[ ]{0,}\\d+(,|\\.)\\d+'\n",
        "    return [re.sub(pattern, ' dinheiro ', r) for r in text_list]\n",
        "\n",
        "# Applying RegEx\n",
        "reviews_money = re_money(reviews_dates)\n",
        "df_comments['re_money'] = reviews_money\n",
        "\n",
        "# Verifying results\n",
        "print_diff(reviews_dates, reviews_money)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo3LG4W42e2i"
      },
      "source": [
        "#### numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QZNM5Ig2e2i",
        "outputId": "2d58acb8-9d6a-4390-e968-18081b251cec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: aparelho eficiente. no site a marca do aparelho esta impresso como 3desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que √© o mesmo aparelho\n",
            "Changed:  aparelho eficiente. no site a marca do aparelho esta impresso como  numero desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que √© o mesmo aparelho\n",
            "\n",
            "Original: Loja nota 10\n",
            "Changed:  Loja nota  numero \n",
            "\n",
            "Original: recebi somente 1 controle Midea Split ESTILO.  Faltou Controle Remoto para Ar Condicionado Consul\n",
            "Changed:  recebi somente  numero  controle Midea Split ESTILO.  Faltou Controle Remoto para Ar Condicionado Consul\n",
            "\n",
            "Original: Este foi o pedido  Balde Com 128 Pe√ßas - Blocos De Montar 2 un -  dinheiro  cada (N√ÉO FOI ENTREGUE)  Vendido e entregue targaryen  Tapete de Eva N¬∫ Letras 36 Pe√ßas Crian√ßas 1 un -  dinheiro  (ESTE FOI ENTREG\n",
            "Changed:  Este foi o pedido  Balde Com  numero  Pe√ßas - Blocos De Montar  numero  un -  dinheiro  cada (N√ÉO FOI ENTREGUE)  Vendido e entregue targaryen  Tapete de Eva N¬∫ Letras  numero  Pe√ßas Crian√ßas  numero  un -  dinheiro  (ESTE FOI ENTREG\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def re_numbers(text_list):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text_series: list object with text content to be prepared [type: list]\n",
        "    \"\"\"\n",
        "\n",
        "    return [re.sub('[0-9]+', ' numero ', r) for r in text_list]\n",
        "\n",
        "reviews_numbers = re_numbers(reviews_money)\n",
        "df_comments['re_numbers'] = reviews_numbers\n",
        "\n",
        "print_diff(reviews_money, reviews_numbers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce6DpA1f2e2j"
      },
      "source": [
        "#### negation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsOpxaDK2e2j",
        "outputId": "9b895e22-33f4-4278-8fc9-9f01718cb006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: N√£o gostei ! Comprei gato por lebre\n",
            "Changed:   nega√ß√£o  gostei ! Comprei gato por lebre\n",
            "\n",
            "Original: Sempre compro pela Internet e a entrega ocorre antes do prazo combinado, que acredito ser o prazo m√°ximo. No stark o prazo m√°ximo j√° se esgotou e ainda n√£o recebi o produto.\n",
            "Changed:  Sempre compro pela Internet e a entrega ocorre antes do prazo combinado, que acredito ser o prazo m√°ximo. No stark o prazo m√°ximo j√° se esgotou e ainda  nega√ß√£o  recebi o produto.\n",
            "\n",
            "Original: O produto n√£o chegou no prazo estipulado e causou transtorno, pq programei a viagem de f√©rias do meu filho, baseado no prazo. Moro na Bahia e ele em Cuiab√° sozinho. Agora, a casa est√° vazia. \n",
            "Changed:  O produto  nega√ß√£o  chegou no prazo estipulado e causou transtorno, pq programei a viagem de f√©rias do meu filho, baseado no prazo. Moro na Bahia e ele em Cuiab√° sozinho. Agora, a casa est√° vazia. \n",
            "\n",
            "Original: Produto bom, por√©m o que veio para mim n√£o condiz com a foto do an√∫ncio.\n",
            "Changed:  Produto bom, por√©m o que veio para mim  nega√ß√£o  condiz com a foto do an√∫ncio.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def re_negation(text_list):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text_series: list object with text content to be prepared [type: list]\n",
        "    \"\"\"\n",
        "\n",
        "    return [re.sub('([nN][√£√ÉaA][oO]|[√±√ë]| [nN] )', ' nega√ß√£o ', r) for r in text_list]\n",
        "\n",
        "reviews_negation = re_negation(reviews_numbers)\n",
        "df_comments['re_negation'] = reviews_negation\n",
        "\n",
        "print_diff(reviews_numbers, reviews_negation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwVZfy522e2k"
      },
      "source": [
        "##### special characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwTb3zgG2e2k",
        "outputId": "43a02c72-c965-45ac-be58-517e289a11c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: Recebi bem antes do prazo estipulado.\n",
            "Changed:  Recebi bem antes do prazo estipulado \n",
            "\n",
            "Original: aparelho eficiente. no site a marca do aparelho esta impresso como  numero desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que √© o mesmo aparelho\n",
            "Changed:  aparelho eficiente  no site a marca do aparelho esta impresso como  numero desinfector e ao chegar esta com outro nome   atualizar com a marca correta uma vez que √© o mesmo aparelho\n",
            "\n",
            "Original: Mas um pouco ,travando...pelo valor ta Boa.  \n",
            "Changed:  Mas um pouco  travando   pelo valor ta Boa   \n",
            "\n",
            "Original: Vendedor confi√°vel, produto ok e entrega antes do prazo.\n",
            "Changed:  Vendedor confi√°vel  produto ok e entrega antes do prazo \n",
            "\n",
            "Original: GOSTARIA DE SABER O QUE HOUVE, SEMPRE RECEBI E ESSA COMPRA AGORA ME DECPCIONOU\n",
            "Changed:  GOSTARIA DE SABER O QUE HOUVE  SEMPRE RECEBI E ESSA COMPRA AGORA ME DECPCIONOU\n",
            "\n",
            "Original: A compra foi realizada facilmente.  A entrega foi efetuada muito antes do prazo dado.  O produto j√° come√ßou a ser usado e at√© o presente,  sem problemas.\n",
            "Changed:  A compra foi realizada facilmente   A entrega foi efetuada muito antes do prazo dado   O produto j√° come√ßou a ser usado e at√© o presente   sem problemas \n",
            "\n"
          ]
        }
      ],
      "source": [
        "def re_special_chars(text_list):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text_series: list object with text content to be prepared [type: list]\n",
        "    \"\"\"\n",
        "\n",
        "    return [re.sub('\\W', ' ', r) for r in text_list]\n",
        "\n",
        "reviews_special_chars = re_special_chars(reviews_negation)\n",
        "df_comments['re_special_chars'] = reviews_special_chars\n",
        "\n",
        "print_diff(reviews_negation, reviews_special_chars, limit=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPuqhOJz2e2k"
      },
      "source": [
        "##### whitespaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZcyCaL02e2l",
        "outputId": "63dc9094-01f7-4dd4-dbd1-97e6dd47d899"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: Recebi bem antes do prazo estipulado \n",
            "Changed:  Recebi bem antes do prazo estipulado\n",
            "\n",
            "Original: aparelho eficiente  no site a marca do aparelho esta impresso como  numero desinfector e ao chegar esta com outro nome   atualizar com a marca correta uma vez que √© o mesmo aparelho\n",
            "Changed:  aparelho eficiente no site a marca do aparelho esta impresso como numero desinfector e ao chegar esta com outro nome atualizar com a marca correta uma vez que √© o mesmo aparelho\n",
            "\n",
            "Original: Mas um pouco  travando   pelo valor ta Boa   \n",
            "Changed:  Mas um pouco travando pelo valor ta Boa\n",
            "\n",
            "Original: Vendedor confi√°vel  produto ok e entrega antes do prazo \n",
            "Changed:  Vendedor confi√°vel produto ok e entrega antes do prazo\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def re_whitespaces(text_list):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text_series: list object with text content to be prepared [type: list]\n",
        "    \"\"\"\n",
        "\n",
        "    # Applying regex\n",
        "    white_spaces = [re.sub('\\s+', ' ', r) for r in text_list]\n",
        "    white_spaces_end = [re.sub('[ \\t]+$', '', r) for r in white_spaces]\n",
        "    return white_spaces_end\n",
        "\n",
        "reviews_whitespaces = re_whitespaces(reviews_special_chars)\n",
        "df_comments['re_whitespaces'] = reviews_whitespaces\n",
        "\n",
        "# Verifying results\n",
        "print_diff(reviews_special_chars, reviews_whitespaces)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-3O9Vxr2e2l"
      },
      "source": [
        "##### stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbgVnPFy2e2l",
        "outputId": "33ad18ce-10e7-4c27-fb53-78813e8a8c13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total portuguese stopwords in the nltk.corpous module: 207\n",
            "['a', '√†', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\darth\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Examples of some portuguese stopwords\n",
        "pt_stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "print(f'Total portuguese stopwords in the nltk.corpous module: {len(pt_stopwords)}')\n",
        "print(pt_stopwords[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxzScKdF2e2m",
        "outputId": "93357c3f-fb3f-40c6-c8ea-99a0f96f6ee6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: Recebi bem antes do prazo estipulado\n",
            "Changed:  recebi bem antes prazo estipulado\n",
            "\n",
            "Original: Parab√©ns lojas lannister adorei comprar pela Internet seguro e pr√°tico Parab√©ns a todos feliz P√°scoa\n",
            "Changed:  parab√©ns lojas lannister adorei comprar internet seguro pr√°tico parab√©ns todos feliz p√°scoa\n",
            "\n",
            "Original: aparelho eficiente no site a marca do aparelho esta impresso como numero desinfector e ao chegar esta com outro nome atualizar com a marca correta uma vez que √© o mesmo aparelho\n",
            "Changed:  aparelho eficiente site marca aparelho impresso numero desinfector chegar outro nome atualizar marca correta vez aparelho\n",
            "\n",
            "Original: Mas um pouco travando pelo valor ta Boa\n",
            "Changed:  pouco travando valor ta boa\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Defining a function to remove the stopwords and to lower the comments\n",
        "def stopwords_removal(text, cached_stopwords=nltk.corpus.stopwords.words('portuguese')):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text: list object where the stopwords will be removed [type: list]\n",
        "    cached_stopwords: stopwords to be applied on the process [type: list, default: stopwords.words('portuguese')]\n",
        "    \"\"\"\n",
        "\n",
        "    return [c.lower() for c in text.split() if c.lower() not in cached_stopwords]\n",
        "\n",
        "reviews_stopwords = [' '.join(stopwords_removal(review)) for review in reviews_whitespaces]\n",
        "df_comments['stopwords_removed'] = reviews_stopwords\n",
        "\n",
        "print_diff(reviews_whitespaces, reviews_stopwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2gBO7_F2e2m"
      },
      "source": [
        "##### stemming\n",
        "\n",
        "Stemming is a text normalization process used in Natural Language Processing (NLP) to reduce words to their root or base form. The goal is to group together different forms of a word so they can be analyzed as a single item. For example, the words \"running\", \"runner\", and \"ran\" can all be reduced to the root word \"run\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ozVKz0U2e2n",
        "outputId": "0d8f2d6b-dff9-4a74-e449-d4c8e2a6c314"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package rslp to\n",
            "[nltk_data]     C:\\Users\\darth\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download rslp\n",
        "nltk.download('rslp')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65_Dj5fr2e2n",
        "outputId": "d0510dc3-3bfe-4372-ba27-195efbfc0334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: recebi bem antes prazo estipulado\n",
            "Changed:  receb bem ant praz estipul\n",
            "\n",
            "Original: parab√©ns lojas lannister adorei comprar internet seguro pr√°tico parab√©ns todos feliz p√°scoa\n",
            "Changed:  parab√©m loj lannist ador compr internet segur pr√°t parab√©m tod feliz p√°sco\n",
            "\n",
            "Original: aparelho eficiente site marca aparelho impresso numero desinfector chegar outro nome atualizar marca correta vez aparelho\n",
            "Changed:  aparelh efici sit marc aparelh impress numer desinfec cheg outr nom atual marc corret vez aparelh\n",
            "\n",
            "Original: pouco travando valor ta boa\n",
            "Changed:  pouc trav val ta boa\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Defining a function to remove the stopwords and to lower the comments\n",
        "def stemming_process(text, stemmer=nltk.stem.RSLPStemmer()):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text: list object where the stopwords will be removed [type: list]\n",
        "    stemmer: type of stemmer to be applied [type: class, default: RSLPStemmer()]\n",
        "    \"\"\"\n",
        "\n",
        "    return [stemmer.stem(c) for c in text.split()]\n",
        "\n",
        "# Applying stemming and looking at some examples\n",
        "reviews_stemmer = [' '.join(stemming_process(review)) for review in reviews_stopwords]\n",
        "df_comments['stemming'] = reviews_stemmer\n",
        "\n",
        "print_diff(reviews_stopwords, reviews_stemmer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bAqKArZC2e2p"
      },
      "outputs": [],
      "source": [
        "reviews_final = reviews_stemmer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5BN5mhvAICD"
      },
      "source": [
        "#### tokenization and pad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnpp2e-e_9Ue",
        "outputId": "ae425ff4-6d07-45b2-add4-b55a695434bc"
      },
      "outputs": [],
      "source": [
        "# Tokenization and padding\n",
        "# tokenizer = Tokenizer()\n",
        "# tokenizer.fit_on_texts(reviews_final)\n",
        "\n",
        "# reviews_sequences = tokenizer.texts_to_sequences(reviews_final)\n",
        "\n",
        "# max_length = max(len(seq) for seq in reviews_sequences)\n",
        "# reviews_padded = pad_sequences(reviews_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# reviews_padded[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDTJDqb52e2p"
      },
      "source": [
        "# Sentiment Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlTmgJNv2e2q"
      },
      "source": [
        "## Deep Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZSlwHMp2e2r"
      },
      "source": [
        "Dive data into train, validation and test (80%, 10%, 10%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"neuralmind/bert-base-portuguese-cased\"  # or \"microsoft/mdeberta-v3-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name, \n",
        "    num_labels=2,  # binary classification\n",
        ")\n",
        "num_epochs = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        # Tokenize the text\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, num_epochs, train_loader, val_loader, device, patience=3, save_path='transformers_weights'):\n",
        "    import os\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "    \n",
        "    # Number of training steps\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    \n",
        "    # Create scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "    \n",
        "    # Store metrics\n",
        "    best_val_accuracy = 0.0\n",
        "    epochs_without_improvement = 0\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "        \n",
        "        # Training\n",
        "        model.train()\n",
        "        epoch_train_loss = 0\n",
        "        epoch_train_correct = 0\n",
        "        epoch_train_total = 0\n",
        "\n",
        "        for batch in tqdm(train_loader):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            \n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "            \n",
        "            loss = outputs.loss\n",
        "            epoch_train_loss += loss.item()\n",
        "            \n",
        "            # Calculate training accuracy\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            epoch_train_correct += (preds == labels).sum().item()\n",
        "            epoch_train_total += labels.size(0)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            \n",
        "            # Clip gradients\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            \n",
        "            # Update weights\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "        \n",
        "        # Calculate training metrics\n",
        "        avg_train_loss = epoch_train_loss / len(train_loader)\n",
        "        train_accuracy = epoch_train_correct / epoch_train_total\n",
        "        train_losses.append(avg_train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        print(f'Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.4f}')\n",
        "        \n",
        "        # Validation\n",
        "        model.eval()\n",
        "        epoch_val_loss = 0\n",
        "        epoch_val_correct = 0\n",
        "        epoch_val_total = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "                \n",
        "                outputs = model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    labels=labels\n",
        "                )\n",
        "\n",
        "                epoch_val_loss += outputs.loss.item()\n",
        "                preds = torch.argmax(outputs.logits, dim=1)\n",
        "                epoch_val_correct += (preds == labels).sum().item()\n",
        "                epoch_val_total += labels.size(0)\n",
        "        \n",
        "        # Calculate validation metrics\n",
        "        avg_val_loss = epoch_val_loss / len(val_loader)\n",
        "        val_accuracy = epoch_val_correct / epoch_val_total\n",
        "        val_losses.append(avg_val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "        print(f'Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.4f}')\n",
        "\n",
        "        model_save_path = os.path.join(save_path, f'model_epoch_{epoch}.pt') \n",
        "        torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "        # Early stopping logic\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            epochs_without_improvement = 0\n",
        "\n",
        "            model_save_path = os.path.join(save_path, f'best_model{epoch}.pt') \n",
        "            torch.save(model.state_dict(), model_save_path)\n",
        "            print(f\"New best model saved (Accuracy: {best_val_accuracy:.4f})\")\n",
        "\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            print(f\"No improvement for {epochs_without_improvement}/{patience} epochs\")\n",
        "            \n",
        "            if epochs_without_improvement >= patience:\n",
        "                print(f\"Early stopping triggered (no improvement for {patience} epochs)\")\n",
        "                break\n",
        "    \n",
        "    print(f\"\\nTraining complete. Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
        "    \n",
        "    metrics = {\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'val_accuracies': val_accuracies,\n",
        "        'best_val_accuracy': best_val_accuracy\n",
        "    }\n",
        "\n",
        "    return model, metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Prepare data and train\n",
        "# Assuming df_comments is your DataFrame with 'comment' and binary 'score' columns\n",
        "X = reviews_final\n",
        "y = y.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=seed)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ReviewDataset(X_train, y_train, tokenizer)\n",
        "val_dataset = ReviewDataset(X_val, y_val, tokenizer)\n",
        "test_dataset = ReviewDataset(X_test, y_test, tokenizer)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2049, 257, 257)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_loader), len(val_loader), len(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "model = model.to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/2049 [00:05<3:13:30,  5.67s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[36], line 60\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, num_epochs, train_loader, val_loader, device, patience, save_path)\u001b[0m\n\u001b[0;32m     57\u001b[0m epoch_train_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Clip gradients\u001b[39;00m\n\u001b[0;32m     63\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
            "File \u001b[1;32md:\\Code\\Data Science\\Projects\\brazilian-e-commerce-nlp-deep-learning\\.venv\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Code\\Data Science\\Projects\\brazilian-e-commerce-nlp-deep-learning\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Code\\Data Science\\Projects\\brazilian-e-commerce-nlp-deep-learning\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "train_model(model, num_epochs, train_loader, val_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzTEq2ws2e22"
      },
      "source": [
        "## Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "qY32MWj82e23"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(y_true, y_pred):\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.2f}\")\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Satisfied', 'Satisfied'], yticklabels=['Not Satisfied', 'Satisfied'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "def display_predictions(df, y_true, y_pred, n=5):\n",
        "    df['true_label'] = y_true\n",
        "    df['predicted_label'] = y_pred\n",
        "    correct = df[df['true_label'] == df['predicted_label']].sample(n)\n",
        "    incorrect = df[df['true_label'] != df['predicted_label']].sample(n)\n",
        "\n",
        "    print(\"Correct Predictions:\")\n",
        "    print(correct[['comment', 'true_label', 'predicted_label']])\n",
        "    print(\"\\nIncorrect Predictions:\")\n",
        "    print(incorrect[['comment', 'true_label', 'predicted_label']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "ir39dCOF2e23",
        "outputId": "4a283f11-d00a-43d5-80b1-9889df16019c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m129/129\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.80      0.82      1398\n",
            "           1       0.90      0.93      0.91      2700\n",
            "\n",
            "    accuracy                           0.88      4098\n",
            "   macro avg       0.87      0.86      0.87      4098\n",
            "weighted avg       0.88      0.88      0.88      4098\n",
            "\n",
            "Accuracy: 0.88\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "X_array_original = np.array(df_comments['comment'])\n",
        "\n",
        "y_pred = best_lstm_model.predict(X_test)\n",
        "y_pred_binary = np.where(y_pred >= 0.5, 1, 0)\n",
        "\n",
        "# Visualize examples\n",
        "def get_correct_and_incorrect(X_test: np.array, y_test: pd.Series, y_pred: np.array, n=10):\n",
        "    df_test = pd.DataFrame(X_test).iloc[y_test.index]\n",
        "    df_test['true_label'] = y_test.values\n",
        "    df_test['predicted_label'] = y_pred\n",
        "    df_test.columns = ['comment' if i == 0 else col for i, col in enumerate(df_test.columns)]\n",
        "\n",
        "    correct = df_test[df_test['true_label'] == df_test['predicted_label']].sample(n)\n",
        "    incorrect = df_test[df_test['true_label'] != df_test['predicted_label']].sample(n)\n",
        "\n",
        "    return correct, incorrect\n",
        "\n",
        "correct, incorrect = get_correct_and_incorrect(X_array_original, y_test, y_pred_binary)\n",
        "\n",
        "evaluate_model(y_test, y_pred_binary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "Mw5guExz2e24",
        "outputId": "82b21e4d-7a68-4df1-d1f2-0a3abf283be2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct examples:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>true_label</th>\n",
              "      <th>predicted_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28131</th>\n",
              "      <td>Muito bom</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35628</th>\n",
              "      <td>J√° faz mais de 1 m√™s que comprei, e nada de en...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31916</th>\n",
              "      <td>Bom</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30046</th>\n",
              "      <td>Entrega nao foi feita , pedsimo atendimento . ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36677</th>\n",
              "      <td>Gostei muito parab√©ns</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32990</th>\n",
              "      <td>Rel√≥gios Casio s√£o os melhores, principalmente...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18308</th>\n",
              "      <td>olha eu comprei dois produtos mas so foi entre...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4879</th>\n",
              "      <td>Comprei e eles n√£o tinham o produto.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24595</th>\n",
              "      <td>√ìtima lindo..</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3095</th>\n",
              "      <td>excelente</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 comment  true_label  \\\n",
              "28131                                          Muito bom           1   \n",
              "35628  J√° faz mais de 1 m√™s que comprei, e nada de en...           0   \n",
              "31916                                                Bom           1   \n",
              "30046  Entrega nao foi feita , pedsimo atendimento . ...           0   \n",
              "36677                              Gostei muito parab√©ns           1   \n",
              "32990  Rel√≥gios Casio s√£o os melhores, principalmente...           1   \n",
              "18308  olha eu comprei dois produtos mas so foi entre...           0   \n",
              "4879               Comprei e eles n√£o tinham o produto.            0   \n",
              "24595                                      √ìtima lindo..           1   \n",
              "3095                                           excelente           1   \n",
              "\n",
              "       predicted_label  \n",
              "28131                1  \n",
              "35628                0  \n",
              "31916                1  \n",
              "30046                0  \n",
              "36677                1  \n",
              "32990                1  \n",
              "18308                0  \n",
              "4879                 0  \n",
              "24595                1  \n",
              "3095                 1  "
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Correct examples:\")\n",
        "correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "WOlWFqNw2e24",
        "outputId": "1edb448c-fbd5-419b-bcfe-0d89a1726594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Incorrect examples:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>true_label</th>\n",
              "      <th>predicted_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3248</th>\n",
              "      <td>S√≥ que na descri√ß√£o do produto, consta q vem c...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36316</th>\n",
              "      <td>Gostei muito da mercadoria e gostaria de fazer...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39138</th>\n",
              "      <td>Nao entrega o pedido no prazo certo</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14857</th>\n",
              "      <td>Como das outras compras n√£o tive problemas.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23198</th>\n",
              "      <td>Recebi tudo amtes do prazo o teclaclado √© top,...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34638</th>\n",
              "      <td>demorou muito o produto ser entregue eu pensav...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22756</th>\n",
              "      <td>Na descri√ß√£o do produto a base do pendente era...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1147</th>\n",
              "      <td>Arranhador veio com lascas na base por conta d...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4592</th>\n",
              "      <td>Produto id√™ntico ao anunciado. N√£o recebi no p...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12564</th>\n",
              "      <td>√ìtima compra demoro um pouco para chegar mais ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 comment  true_label  \\\n",
              "3248   S√≥ que na descri√ß√£o do produto, consta q vem c...           1   \n",
              "36316  Gostei muito da mercadoria e gostaria de fazer...           1   \n",
              "39138               Nao entrega o pedido no prazo certo            0   \n",
              "14857        Como das outras compras n√£o tive problemas.           1   \n",
              "23198  Recebi tudo amtes do prazo o teclaclado √© top,...           1   \n",
              "34638  demorou muito o produto ser entregue eu pensav...           1   \n",
              "22756  Na descri√ß√£o do produto a base do pendente era...           1   \n",
              "1147   Arranhador veio com lascas na base por conta d...           0   \n",
              "4592   Produto id√™ntico ao anunciado. N√£o recebi no p...           1   \n",
              "12564  √ìtima compra demoro um pouco para chegar mais ...           0   \n",
              "\n",
              "       predicted_label  \n",
              "3248                 0  \n",
              "36316                0  \n",
              "39138                1  \n",
              "14857                0  \n",
              "23198                0  \n",
              "34638                0  \n",
              "22756                0  \n",
              "1147                 1  \n",
              "4592                 0  \n",
              "12564                1  "
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Incorrect examples:\")\n",
        "incorrect\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-nXvQwz2e25"
      },
      "source": [
        "## Dense model with Regex Transformers + TF-IDF Vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tEsKkX32e25"
      },
      "source": [
        "### Feature Extraction\n",
        "\n",
        "After the RegEx, stopwords removal and stemming application, we can use Bag of Words, TF-IDF and Word2Vec to get more meaning. To make our analysis easier, let's define a function that receives a text and a vectorizer object and applies the feature extraction on the respective text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyOoN_BF2e25"
      },
      "source": [
        "#### CountVectorizer\n",
        "\n",
        "Count vectorization is a technique in NLP that converts text documents into a matrix of token counts. Tokens can be words, characters, or n-grams. Each token represents a column in the matrix, and the resulting vector for each document has counts for each token.\n",
        "\n",
        "On the Bag of Words approach, we create a dictionary vocabulary with all the unique words and, for each word in each comment/text string, we index the words into a vector that represents the occurrence (1) or not (0) of each word. This is a way for transforming a text into a frequency vector considering a literal bag of words (dictionary vocabulary).\n",
        "\n",
        "Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVt67_3Y2e26",
        "outputId": "231f1eb0-e93a-4134-ab6d-5840e1866f3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'this': 8,\n",
              " 'is': 3,\n",
              " 'the': 6,\n",
              " 'first': 2,\n",
              " 'document': 1,\n",
              " 'second': 5,\n",
              " 'and': 0,\n",
              " 'third': 7,\n",
              " 'one': 4}"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus = [\n",
        "    'This is the first document',\n",
        "    'This document is the second document',\n",
        "    'and this is the third one',\n",
        "    'is this the first document'\n",
        "]\n",
        "\n",
        "vec = CountVectorizer().fit(corpus)\n",
        "vec.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfgX6YcZ2e26",
        "outputId": "f0d6d1fc-5b84-4e28-c7ed-3b096f417761"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
              "       [0, 2, 0, 1, 0, 1, 1, 0, 1],\n",
              "       [1, 0, 0, 1, 1, 0, 1, 1, 1],\n",
              "       [0, 1, 1, 1, 0, 0, 1, 0, 1]])"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vec.transform(corpus).toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1usMedh2e27"
      },
      "source": [
        "#### TF-IDF\n",
        "\n",
        "With the Bag of Words approach, each word has the same weight, which may not be true all the time, especially for those words with a very low frequency in the corpus. So, the TF-IDF (Term Frequency and Inverse Document Frequency) approach can be used with the scikit-learn library following the formulas:\n",
        "\n",
        "$$\n",
        "TF = \\frac{\\text{Frequency of a word in the document}}{\\text{Total words in the document}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "IDF = \\log\\left(\\frac{\\text{Total number of documents}}{\\text{Number of documents containing the word}}\\right)\n",
        "$$\n",
        "\n",
        "The purpose of using tf-idf instead of simply counting the frequency of a token in a document is to reduce the influence of tokens that appear very frequently in a given collection of documents. These tokens are less informative than those appearing in only a small fraction of the corpus. Scaling down the impact of these frequently occurring tokens helps improve text-based machine-learning models‚Äô accuracy.\n",
        "\n",
        "Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqLh6YU_2e27",
        "outputId": "ed8c12cd-949c-474c-a4e5-6049344ddc5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
              "        0.        , 0.38408524, 0.        , 0.38408524],\n",
              "       [0.        , 0.6876236 , 0.        , 0.28108867, 0.        ,\n",
              "        0.53864762, 0.28108867, 0.        , 0.28108867],\n",
              "       [0.51184851, 0.        , 0.        , 0.26710379, 0.51184851,\n",
              "        0.        , 0.26710379, 0.51184851, 0.26710379],\n",
              "       [0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
              "        0.        , 0.38408524, 0.        , 0.38408524]])"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorized = vec.transform(corpus).toarray()\n",
        "tfid = TfidfTransformer().fit(vectorized)\n",
        "\n",
        "tfid.transform(vectorized).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "Sc9MiVU_2e27"
      },
      "outputs": [],
      "source": [
        "# [TEXT PREP] Class to apply multiple RegEx functions on a dict\n",
        "class ApplyRegex(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, regex_transformers):\n",
        "        self.regex_transformers = regex_transformers\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        # Applying all regex functions in the regex_transformers dictionary\n",
        "        for regex_name, regex_function in self.regex_transformers.items():\n",
        "            X = regex_function(X)\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "# [TEXT PREP] Class to remove stopwords\n",
        "class StopWordsRemoval(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, text_stopwords):\n",
        "        self.text_stopwords = text_stopwords\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return [' '.join(stopwords_removal(comment, self.text_stopwords)) for comment in X]\n",
        "\n",
        "\n",
        "# [TEXT PREP] Class to apply stemming\n",
        "class StemmingProcess(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, stemmer):\n",
        "        self.stemmer = stemmer\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return [' '.join(stemming_process(comment, self.stemmer)) for comment in X]\n",
        "\n",
        "\n",
        "# [TEXT PREP] Class to extract features (vocab / bag of words / TF-IDF)\n",
        "class TextFeatureExtraction(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, vectorizer, train=True):\n",
        "        self.vectorizer = vectorizer\n",
        "        self.train = train\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        if self.train:\n",
        "            return self.vectorizer.fit_transform(X).toarray()\n",
        "        else:\n",
        "            return self.vectorizer.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "WWuSW3LX2e28"
      },
      "outputs": [],
      "source": [
        "# Defining regex transformers to be applied\n",
        "regex_transformers = {\n",
        "    'break_line': re_breakline,\n",
        "    'hiperlinks': re_hiperlinks,\n",
        "    'dates': re_dates,\n",
        "    'money': re_money,\n",
        "    'numbers': re_numbers,\n",
        "    'negation': re_negation,\n",
        "    'special_chars': re_special_chars,\n",
        "    'whitespaces': re_whitespaces\n",
        "}\n",
        "\n",
        "# Defining the vectorizer to extract features from text\n",
        "vectorizer = TfidfVectorizer(max_features=300, min_df=7, max_df=0.8, stop_words=pt_stopwords)\n",
        "\n",
        "# Building the Pipeline\n",
        "text_pipeline = Pipeline([\n",
        "    ('regex', ApplyRegex(regex_transformers)),\n",
        "    ('stopwords', StopWordsRemoval(nltk.corpus.stopwords.words('portuguese'))),\n",
        "    ('stemming', StemmingProcess(nltk.stem.RSLPStemmer())),\n",
        "    ('text_features', TextFeatureExtraction(vectorizer))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4qCk9Q_2e28"
      },
      "source": [
        "* max_features=300: indicates that the matrix will be created using the 300 most common words from the corpus\n",
        "* max_df=0.8: indicates that we will use only words with at least 80% frequency in the corpus\n",
        "* min_df=7: indicates that we will use only words that occurs in at least 7 text strings in the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "gUUOoFpy2e29"
      },
      "outputs": [],
      "source": [
        "X = df_comments['comment']\n",
        "\n",
        "X_transformed = text_pipeline.fit_transform(reviews_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "0an69owE2e29"
      },
      "outputs": [],
      "source": [
        "X_train_trans, X_val_trans, X_test_trans, y_train_trans, y_val_trans, y_test_trans = train_val_test_split(X_transformed, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvP0jDeT2e29",
        "outputId": "00099d29-4103-4a6a-9cf3-eb53cde9dfb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.43824671,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.32527411, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.25943248, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.27427872, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.65831002, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.29037051,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.2047326 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ])"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_trans[500]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjpl-lV12e3B"
      },
      "source": [
        "## Test with sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "NHtxNJz82e3B"
      },
      "outputs": [],
      "source": [
        "def test_new_sentence_lstm(new_sentence, model, tokenizer=tokenizer, max_sequence_length=max_length):\n",
        "    regex_transformers = {\n",
        "        'break_line': re_breakline,\n",
        "        'hiperlinks': re_hiperlinks,\n",
        "        'dates': re_dates,\n",
        "        'money': re_money,\n",
        "        'numbers': re_numbers,\n",
        "        'negation': re_negation,\n",
        "        'special_chars': re_special_chars,\n",
        "        'whitespaces': re_whitespaces\n",
        "    }\n",
        "\n",
        "\n",
        "    # Pre-process\n",
        "    regex = ApplyRegex(regex_transformers)\n",
        "    sentence_processed = regex.transform([new_sentence])\n",
        "    sentence_processed = [' '.join(stopwords_removal(review)) for review in sentence_processed]\n",
        "    sentence_processed = [' '.join(stemming_process(review)) for review in sentence_processed]\n",
        "\n",
        "    print(sentence_processed)\n",
        "\n",
        "    # Tokenizer and padding e aplicando padding\n",
        "    tokenized_sentence = tokenizer.texts_to_sequences(sentence_processed)\n",
        "    padded_sentence = pad_sequences(tokenized_sentence, maxlen=max_sequence_length, padding=\"post\")\n",
        "    print(padded_sentence)\n",
        "\n",
        "    # Result\n",
        "    prediction = model.predict(padded_sentence)\n",
        "    print(prediction)\n",
        "\n",
        "    review = \"positive\" if prediction >= 0.5 else \"negative\"\n",
        "    print(f\"The sentence represents a {review} review!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BHxy-qI2e3C",
        "outputId": "9ddc40ed-40df-49ed-bd16-9a657e30c4c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['compr gift card aind esper cheg produt digit tod sit mand instant vulg mai am√©r latin simples neg conseg entreg simpl c√≥dig mail neg recom servi√ß p√©ss']\n",
            "[[   5 3568   19   27    7    1  943   38   35  114 3512  204 1199  411\n",
            "     2  832    3  322  487  232    2   11  182  126    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "[[0.04152721]]\n",
            "The sentence represents a negative review!\n"
          ]
        }
      ],
      "source": [
        "new_sentence = 'Comprei um gift card e ainda estou esperando chegar, √© um produto digital, todos os sites mandam no mesmo instante, \\\n",
        "e o vulgo \"maior da Am√©rica Latina\" simplesmente n√£o consegue entregar um simples c√≥digo no e-mail. N√£o recomendo, servi√ßo p√©ssimo.'\n",
        "test_new_sentence_lstm(new_sentence, best_lstm_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTA1Ac542e3C",
        "outputId": "b35fd240-cf9d-4188-bef2-5841f72cd028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['estud institu selecion receb benef√≠ci pae semestr numer numer receb pag benef√≠ci m√™ pass atras m√™ aind neg receb coleg selecion benef√≠ci fal receb numer numer tod poi m√™ pass receb numer m√™ numer mand mail busc ajud respond esper numer dia utel lig mand retorn segund feir numer novembr hoj lig descobr folh pag fech receb pag jan solic benef√≠ci expliq solicit poi atrav√©s mant desp estud almo√ß transport benef√≠ci neg consegu continu estud univers agor esper jan cont err institu pod corr risc neg consegu assist aul cont falt transport']\n",
            "[[ 489    8   53  964  871  377 4841   95   39  721  571 3132 1765 3504\n",
            "   240  377    2  252  231 1765 1422   52   27  964  216   79 4086   72\n",
            "   431  427    2  252 1134 6632  216   45  240]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "[[0.27401313]]\n",
            "The sentence represents a negative review!\n"
          ]
        }
      ],
      "source": [
        "new_sentence='Sou estudante da institui√ß√£o e fui selecionada para receber o benef√≠cio PAES no semestre 2024.1, \\\n",
        "recebi o pagamento do benef√≠cio do m√™s passado com atraso e este m√™s ainda n√£o recebi. Colegas que tamb√©m foram selecionados pelo benef√≠cio,\\\n",
        "falaram que j√° receberam 1.200 ao todo, pois no m√™s passado receberam 800 e este m√™s, 400. Mandei e-mails em busca de uma ajuda e me \\\n",
        "responderam para esperar os 10 dias uteis, liguei e me mandaram retornar na segunda-feira, 18 de novembro (hoje) e ao ligar, descobri que a \\\n",
        "folha de pagamento fechou e s√≥ receberei o meu pagamento em janeiro. Ao solicitar esse benef√≠cio, expliquei que estava solicitando pois atrav√©s \\\n",
        "dele, eu manteria as minhas despesas como estudante (almo√ßo e transporte) e sem este benef√≠cio, eu n√£o conseguiria continuar estudando na universidade.\\\n",
        "Agora terei que esperar at√© janeiro por conta de um erro da institui√ß√£o, podendo correr o risco de n√£o conseguir assistir as aulas por conta da falta de transporte.'\n",
        "test_new_sentence_lstm(new_sentence, best_lstm_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfgJyy1N2e3D",
        "outputId": "0c518865-a3e8-43a9-e000-b2bf8b8de5e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['sit post comunic prim respost verific document mand edit diz pod reenvi document cas neg compat inscr por√©m sit consult neg d√£o op√ß reenvi soment consult document envi anteri']\n",
            "[[  35  348  428  130  120  464 1249  114  145   72  948 1249  109    2\n",
            "   598   44   35 1289    2  834  546  948  122 1289 1249   56  642    0\n",
            "     0    0    0    0    0    0    0    0    0]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "[[0.18486482]]\n",
            "The sentence represents a negative review!\n"
          ]
        }
      ],
      "source": [
        "new_sentence='O SITE POSTOU UM COMUNICADO COM A PRIMEIRA RESPOSTA DA VERIFICA√á√ÉO DOS DOCUMENTOS E MANDOU UM EDITAL DIZENDO QUE EU PODERIA REENVIAR OS DOCUMENTOS CASO N√ÉO TIVESSE COMPAT√çVEL COM A INSCRI√á√ÉO. POR√âM, NO SITE DE CONSULTA, N√ÉO ME D√ÉO A OP√á√ÉO DE REENVIAR, MAS SOMENTE A DE CONSULTAR O DOCUMENTOS QUE J√Å ENVIEI ANTERIORMENTE.'\n",
        "test_new_sentence_lstm(new_sentence, best_lstm_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms9XhS9p2e3D",
        "outputId": "b9777bcf-27ce-44a1-97cf-1504a9aaa955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['excel produt pessoal parab legal gost volt']\n",
            "[[ 23   1 688 298 430  17 123   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "[[0.97859794]]\n",
            "The sentence represents a positive review!\n"
          ]
        }
      ],
      "source": [
        "new_sentence='Excelente produto pessoal, parabens, legal, gostei, voltarei!'\n",
        "test_new_sentence_lstm(new_sentence, best_lstm_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r86jYtCR2e3D",
        "outputId": "9c804fc1-4fd9-4f3b-f08d-a63eda5f9ec2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['neg palavr descrev qu√£ espec mim sei caix mens dev chei poi pesso quer tod gost relembr tod car sint qu√£ grat ter vid hoj quer desej feliz anivers√°ri dia muit celebr abra√ß apert sorris sincer lad pesso ama esper pod celebr muit outr ano contig parab√©m dia']\n",
            "[[ 191  101  410   75  814   39  358   61   38   17   38  198  885  417\n",
            "    69 1107  134   61  230  288  933   21  179  927  930 6649 2251  671\n",
            "   358 3362   27   72  179   32  308   48   21]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "[[0.7218724]]\n",
            "The sentence represents a positive review!\n"
          ]
        }
      ],
      "source": [
        "new_sentence='N√£o tenho palavras para descrever o qu√£o especial voc√™ √© para mim. Sei que sua caixa de mensagens deve estar cheia, pois voc√™ √© uma pessoa muito querida por todos. Mas gostaria de te relembrar todo o carinho que sinto por voc√™ e qu√£o grato eu sou por te ter na minha vida.\\\n",
        "Hoje, quero lhe desejar o mais feliz dos anivers√°rios. Que esse dia seja de muita celebra√ß√£o, abra√ßos apertados e sorrisos sinceros ao lado das pessoas que voc√™ mais ama. Espero poder celebrar muitos outros anos contigo.\\\n",
        "Parab√©ns pelo seu dia.'\n",
        "test_new_sentence_lstm(new_sentence, best_lstm_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
