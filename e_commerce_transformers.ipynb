{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khAinpqS2e2S",
        "outputId": "375737ec-efbd-40b0-b283-82b150fca62a"
      },
      "outputs": [],
      "source": [
        "# !pip install kagglehub\n",
        "# !pip install pandas\n",
        "# !pip install nltk\n",
        "# !pip install scikit-learn\n",
        "# !pip install tensorflow\n",
        "# !pip install matplotlib\n",
        "# !pip install seaborn\n",
        "# !pip install torch\n",
        "# !pip install transformers\n",
        "# !pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vrFm_hUc2e2W"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Code\\Data Science\\Projects\\brazilian-e-commerce-nlp-deep-learning\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForSequenceClassification,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALRsADqg2e2Y"
      },
      "source": [
        "\n",
        "\n",
        "olist_customers_dataset.csv\n",
        "olist_geolocation_dataset.csv\n",
        "olist_orders_dataset.csv\n",
        "olist_order_items_dataset.csv\n",
        "olist_order_payments_dataset.csv\n",
        "olist_order_reviews_dataset.csv\n",
        "olist_products_dataset.csv\n",
        "olist_sellers_dataset.csv\n",
        "product_category_name_translation.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6YFwdkk2e2Z"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use the [Brazilian E-Commerce](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce) dataset, which contains reviews from products bought in e-commerces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQhAn17h2e2Z",
        "outputId": "6eeedf27-40ae-4ac9-c5d3-e6d1b7e218be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.11).\n",
            "Path to dataset files: C:\\Users\\darth\\.cache\\kagglehub\\datasets\\olistbr\\brazilian-ecommerce\\versions\\2\n"
          ]
        }
      ],
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"olistbr/brazilian-ecommerce\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mUmuSvIW2e2a"
      },
      "outputs": [],
      "source": [
        "# Reading all the files\n",
        "# olist_customer = pd.read_csv(path + 'olist_customers_dataset.csv')\n",
        "# olist_geolocation = pd.read_csv(path + 'olist_geolocation_dataset.csv')\n",
        "# olist_orders = pd.read_csv(path + 'olist_orders_dataset.csv')\n",
        "# olist_order_items = pd.read_csv(path + 'olist_order_items_dataset.csv')\n",
        "# olist_order_payments = pd.read_csv(path + 'olist_order_payments_dataset.csv')\n",
        "olist_order_reviews = pd.read_csv(path + '//olist_order_reviews_dataset.csv')\n",
        "# olist_products = pd.read_csv(path + 'olist_products_dataset.csv')\n",
        "# olist_sellers = pd.read_csv(path + 'olist_sellers_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Ft2GFMdD2e2b",
        "outputId": "922b95ba-3378-4287-8975-f114cde36069"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>99224.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.086421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.347579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       review_score\n",
              "count  99224.000000\n",
              "mean       4.086421\n",
              "std        1.347579\n",
              "min        1.000000\n",
              "25%        4.000000\n",
              "50%        5.000000\n",
              "75%        5.000000\n",
              "max        5.000000"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "olist_order_reviews.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "mnrdQZrK2e2b",
        "outputId": "88964732-d970-4e05-d6c0-152a67918116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (40977, 2)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>Recebi bem antes do prazo estipulado.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Vendedor confiável, produto ok e entrega antes...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   score                                            comment\n",
              "0      5              Recebi bem antes do prazo estipulado.\n",
              "1      5  Parabéns lojas lannister adorei comprar pela I...\n",
              "2      4  aparelho eficiente. no site a marca do aparelh...\n",
              "3      4    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n\n",
              "4      5  Vendedor confiável, produto ok e entrega antes..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_comments = olist_order_reviews.loc[:, ['review_score', 'review_comment_message']]\n",
        "df_comments = df_comments.dropna(subset=['review_comment_message'])\n",
        "df_comments = df_comments.reset_index(drop=True)\n",
        "\n",
        "print(f'Dataset shape: {df_comments.shape}')\n",
        "df_comments.columns = ['score', 'comment']\n",
        "df_comments.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzukufS62e2c"
      },
      "source": [
        "We will consider a binary classification problem, with negative comments being with score below 4 and good reviews being 4 and 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls4hqbJp2e2c",
        "outputId": "f2de4453-4256-491a-c7c8-30619d9fc00e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "40977"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = df_comments['score']\n",
        "y = y.apply(lambda x: 0 if x < 4 else 1)\n",
        "\n",
        "len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "DMUW1FgP2e2d",
        "outputId": "bfdfbf81-f37b-407e-9609-ae6992f432ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "score\n",
              "1    26530\n",
              "0    14447\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.value_counts(sort=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Leu95p52e2e"
      },
      "source": [
        "We have almost 41k comments that could be used for training a sentimental analysis model. But, beforehand we have to do some preprocessing on the text to transform the comment input into a vector that can be interpreted for a Machine Learning model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_0RZMgi2e2e"
      },
      "source": [
        "## Natural language processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri09aDIL2e2e"
      },
      "source": [
        "### Regular expressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0xqUjBg2e2e"
      },
      "source": [
        "First lest's define a function to help visualize transformations on data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_Y83EHtQ2e2f"
      },
      "outputs": [],
      "source": [
        "def print_diff(dataset_original, dataset_changed, limit=4):\n",
        "    # Print the original and changed values from lists\n",
        "    count = 0\n",
        "    for original, modified in zip(dataset_original, dataset_changed):\n",
        "        if original != modified:\n",
        "            print(f'Original: {original}')\n",
        "            print(f'Changed:  {modified}')\n",
        "            print('')\n",
        "            count += 1\n",
        "            if count >= limit:\n",
        "                break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuRcNIUe2e2f"
      },
      "source": [
        "##### \\n and \\r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWrE_R6E2e2f"
      },
      "source": [
        "As long as we consider the global internet as the source of our comments, probably we have to deal with some HTML tags, break lines, special characteres and other content that could be part of the dataset. Let's dig a little bit more on Regular Expressions to search for those patterns.\n",
        "\n",
        "First of all, let's define a function that will be used for analysing the results of an applied regular expression. With this we can validate our text pre processing in an easier way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAr5oCeT2e2g",
        "outputId": "2183de62-af26-4ebb-f14d-b260dc4e62a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: Mas um pouco ,travando...pelo valor ta Boa.\n",
            "\n",
            "Changed:  Mas um pouco ,travando...pelo valor ta Boa.  \n",
            "\n",
            "Original: A compra foi realizada facilmente.\n",
            "A entrega foi efetuada muito antes do prazo dado.\n",
            "O produto já começou a ser usado e até o presente,\n",
            "sem problemas.\n",
            "Changed:  A compra foi realizada facilmente.  A entrega foi efetuada muito antes do prazo dado.  O produto já começou a ser usado e até o presente,  sem problemas.\n",
            "\n",
            "Original: recebi somente 1 controle Midea Split ESTILO.\n",
            "Faltou Controle Remoto para Ar Condicionado Consul\n",
            "Changed:  recebi somente 1 controle Midea Split ESTILO.  Faltou Controle Remoto para Ar Condicionado Consul\n",
            "\n",
            "Original: Ocorreu tudo como contratado sendo a entrega realizada antes do prazo \n",
            " Estou satisfeita\n",
            "\n",
            "Changed:  Ocorreu tudo como contratado sendo a entrega realizada antes do prazo    Estou satisfeita  \n",
            "\n"
          ]
        }
      ],
      "source": [
        "def re_breakline(text_list):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text_list: list object with text content to be prepared [type: list]\n",
        "    \"\"\"\n",
        "\n",
        "    # Applying regex\n",
        "    return [re.sub('[\\n\\r]', ' ', r) for r in text_list]\n",
        "\n",
        "# Creating a list of comment reviews\n",
        "reviews = list(df_comments['comment'].values)\n",
        "\n",
        "# Applying RegEx\n",
        "reviews_breakline = re_breakline(reviews)\n",
        "df_comments['re_breakline'] = reviews_breakline\n",
        "\n",
        "# Verifying results\n",
        "print_diff(reviews, reviews_breakline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Word substitution\n",
        "\n",
        "We will substitute some metadata for a word representing the concept. The main idea is to generalize the concept, making it easier for the model to get more information from this data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTrs1rQt2e2g"
      },
      "source": [
        "##### links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLdPtI6b2e2g",
        "outputId": "3f36f3bb-5d99-4908-a103-82790e588448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: comprei o produto pela cor ilustrada pelo site da loja americana, no site mostra ser preto http://prntscr.com/jkx7hr quando o produto chegou aqui veio todos com a mesma cor, tabaco http://prntscr.com/\n",
            "Changed:  comprei o produto pela cor ilustrada pelo site da loja americana, no site mostra ser preto  link  quando o produto chegou aqui veio todos com a mesma cor, tabaco  link \n",
            "\n"
          ]
        }
      ],
      "source": [
        "def re_hiperlinks(text_list):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text_list: list object with text content to be prepared [type: list]\n",
        "    \"\"\"\n",
        "\n",
        "    # Applying regex\n",
        "    pattern = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
        "    return [re.sub(pattern, ' link ', r) for r in text_list]\n",
        "\n",
        "# Applying RegEx\n",
        "reviews_hiperlinks = re_hiperlinks(reviews_breakline)\n",
        "df_comments['re_hiperlinks'] = reviews_hiperlinks\n",
        "\n",
        "# Printing differences\n",
        "print_diff(reviews_breakline, reviews_hiperlinks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx4Da0j22e2h"
      },
      "source": [
        "##### dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiX7V5Jx2e2h",
        "outputId": "e1a59983-ad76-4678-e20c-f73ece627f53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: A targaryen não é de confiança não entregou a minha compra e colocou no rastreamento do pedido que foi entregue no dia 14/12/17 empresa falsa quero receber meus produtos que foram pagos com boleto bancari\n",
            "Changed:  A targaryen não é de confiança não entregou a minha compra e colocou no rastreamento do pedido que foi entregue no dia  data  empresa falsa quero receber meus produtos que foram pagos com boleto bancari\n",
            "\n",
            "Original: ENTREGA MUITO DEMORADA, COMPREI EM 26/03/2018 E ATÉ AGORA NÃO RECEBI OS PRODUTOS\n",
            "Changed:  ENTREGA MUITO DEMORADA, COMPREI EM  data  E ATÉ AGORA NÃO RECEBI OS PRODUTOS\n",
            "\n",
            "Original: ainda nao recebi e a ultima informacao sobre p produto e do dia 08/12/2017.\n",
            "Changed:  ainda nao recebi e a ultima informacao sobre p produto e do dia  data .\n",
            "\n",
            "Original: Comprei duas bonecas baby kiss Sid nil dia 07/12/17 e eles entregaram somente 1 boneca ,não veio junto nota fiscal,caixa amassada e também não consigo contato com a lannister o telefone só da ocupado\n",
            "Changed:  Comprei duas bonecas baby kiss Sid nil dia  data  e eles entregaram somente 1 boneca ,não veio junto nota fiscal,caixa amassada e também não consigo contato com a lannister o telefone só da ocupado\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def re_dates(text_list):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text_list: list object with text content to be prepared [type: list]\n",
        "    \"\"\"\n",
        "\n",
        "    # Applying regex\n",
        "    pattern = '([0-2][0-9]|(3)[0-1])(\\/|\\.)(((0)[0-9])|((1)[0-2]))(\\/|\\.)\\d{2,4}'\n",
        "    return [re.sub(pattern, ' data ', r) for r in text_list]\n",
        "\n",
        "\n",
        "# Applying RegEx\n",
        "reviews_dates = re_dates(reviews_hiperlinks)\n",
        "df_comments['re_dates'] = reviews_dates\n",
        "\n",
        "# Verifying results\n",
        "print_diff(reviews_hiperlinks, reviews_dates)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atie-uYj2e2h"
      },
      "source": [
        "##### money"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP2RbQS22e2i",
        "outputId": "e46539ea-e70b-41e0-c0c5-6ac0058c0b84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: Este foi o pedido  Balde Com 128 Peças - Blocos De Montar 2 un - R$ 25,00 cada (NÃO FOI ENTREGUE)  Vendido e entregue targaryen  Tapete de Eva Nº Letras 36 Peças Crianças 1 un - R$ 35,90 (ESTE FOI ENTREG\n",
            "Changed:  Este foi o pedido  Balde Com 128 Peças - Blocos De Montar 2 un -  dinheiro  cada (NÃO FOI ENTREGUE)  Vendido e entregue targaryen  Tapete de Eva Nº Letras 36 Peças Crianças 1 un -  dinheiro  (ESTE FOI ENTREG\n",
            "\n",
            "Original: Comprei 4 produtos, sendo que só recebi 3. Faltou um lençol branco sem elástico. Foi quase R$ 100,00. E como eu fico? No prejuizo?\n",
            "Changed:  Comprei 4 produtos, sendo que só recebi 3. Faltou um lençol branco sem elástico. Foi quase  dinheiro . E como eu fico? No prejuizo?\n",
            "\n",
            "Original: Relógio belíssimo, muito elegante, inacreditável diante do valor de menos de R$ 150,00! Veio muito bem embrulhado e protegido, fora que tem também caixa muito chique, como se fosse jóia!!! Recomendo\n",
            "Changed:  Relógio belíssimo, muito elegante, inacreditável diante do valor de menos de  dinheiro ! Veio muito bem embrulhado e protegido, fora que tem também caixa muito chique, como se fosse jóia!!! Recomendo\n",
            "\n",
            "Original: Entrega super rápida. Quanto ao produto, não gostei tanto, imaginei que seria melhor e mais bonito, se tivesse visto em uma loja, pegado em mãos antes não teria pagado R$21,90 não, mas ok.\n",
            "Changed:  Entrega super rápida. Quanto ao produto, não gostei tanto, imaginei que seria melhor e mais bonito, se tivesse visto em uma loja, pegado em mãos antes não teria pagado  dinheiro  não, mas ok.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def re_money(text_list):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text_list: list object with text content to be prepared [type: list]\n",
        "    \"\"\"\n",
        "\n",
        "    # Applying regex\n",
        "    pattern = '[R]{0,1}\\$[ ]{0,}\\d+(,|\\.)\\d+'\n",
        "    return [re.sub(pattern, ' dinheiro ', r) for r in text_list]\n",
        "\n",
        "# Applying RegEx\n",
        "reviews_money = re_money(reviews_dates)\n",
        "df_comments['re_money'] = reviews_money\n",
        "\n",
        "# Verifying results\n",
        "print_diff(reviews_dates, reviews_money)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo3LG4W42e2i"
      },
      "source": [
        "#### numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QZNM5Ig2e2i",
        "outputId": "2d58acb8-9d6a-4390-e968-18081b251cec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: aparelho eficiente. no site a marca do aparelho esta impresso como 3desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho\n",
            "Changed:  aparelho eficiente. no site a marca do aparelho esta impresso como  numero desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho\n",
            "\n",
            "Original: Loja nota 10\n",
            "Changed:  Loja nota  numero \n",
            "\n",
            "Original: recebi somente 1 controle Midea Split ESTILO.  Faltou Controle Remoto para Ar Condicionado Consul\n",
            "Changed:  recebi somente  numero  controle Midea Split ESTILO.  Faltou Controle Remoto para Ar Condicionado Consul\n",
            "\n",
            "Original: Este foi o pedido  Balde Com 128 Peças - Blocos De Montar 2 un -  dinheiro  cada (NÃO FOI ENTREGUE)  Vendido e entregue targaryen  Tapete de Eva Nº Letras 36 Peças Crianças 1 un -  dinheiro  (ESTE FOI ENTREG\n",
            "Changed:  Este foi o pedido  Balde Com  numero  Peças - Blocos De Montar  numero  un -  dinheiro  cada (NÃO FOI ENTREGUE)  Vendido e entregue targaryen  Tapete de Eva Nº Letras  numero  Peças Crianças  numero  un -  dinheiro  (ESTE FOI ENTREG\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def re_numbers(text_list):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text_series: list object with text content to be prepared [type: list]\n",
        "    \"\"\"\n",
        "\n",
        "    return [re.sub('[0-9]+', ' numero ', r) for r in text_list]\n",
        "\n",
        "reviews_numbers = re_numbers(reviews_money)\n",
        "df_comments['re_numbers'] = reviews_numbers\n",
        "\n",
        "print_diff(reviews_money, reviews_numbers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce6DpA1f2e2j"
      },
      "source": [
        "#### negation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsOpxaDK2e2j",
        "outputId": "9b895e22-33f4-4278-8fc9-9f01718cb006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: Não gostei ! Comprei gato por lebre\n",
            "Changed:   negação  gostei ! Comprei gato por lebre\n",
            "\n",
            "Original: Sempre compro pela Internet e a entrega ocorre antes do prazo combinado, que acredito ser o prazo máximo. No stark o prazo máximo já se esgotou e ainda não recebi o produto.\n",
            "Changed:  Sempre compro pela Internet e a entrega ocorre antes do prazo combinado, que acredito ser o prazo máximo. No stark o prazo máximo já se esgotou e ainda  negação  recebi o produto.\n",
            "\n",
            "Original: O produto não chegou no prazo estipulado e causou transtorno, pq programei a viagem de férias do meu filho, baseado no prazo. Moro na Bahia e ele em Cuiabá sozinho. Agora, a casa está vazia. \n",
            "Changed:  O produto  negação  chegou no prazo estipulado e causou transtorno, pq programei a viagem de férias do meu filho, baseado no prazo. Moro na Bahia e ele em Cuiabá sozinho. Agora, a casa está vazia. \n",
            "\n",
            "Original: Produto bom, porém o que veio para mim não condiz com a foto do anúncio.\n",
            "Changed:  Produto bom, porém o que veio para mim  negação  condiz com a foto do anúncio.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def re_negation(text_list):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text_series: list object with text content to be prepared [type: list]\n",
        "    \"\"\"\n",
        "\n",
        "    return [re.sub('([nN][ãÃaA][oO]|[ñÑ]| [nN] )', ' negação ', r) for r in text_list]\n",
        "\n",
        "reviews_negation = re_negation(reviews_numbers)\n",
        "df_comments['re_negation'] = reviews_negation\n",
        "\n",
        "print_diff(reviews_numbers, reviews_negation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwVZfy522e2k"
      },
      "source": [
        "##### special characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwTb3zgG2e2k",
        "outputId": "43a02c72-c965-45ac-be58-517e289a11c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: Recebi bem antes do prazo estipulado.\n",
            "Changed:  Recebi bem antes do prazo estipulado \n",
            "\n",
            "Original: aparelho eficiente. no site a marca do aparelho esta impresso como  numero desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho\n",
            "Changed:  aparelho eficiente  no site a marca do aparelho esta impresso como  numero desinfector e ao chegar esta com outro nome   atualizar com a marca correta uma vez que é o mesmo aparelho\n",
            "\n",
            "Original: Mas um pouco ,travando...pelo valor ta Boa.  \n",
            "Changed:  Mas um pouco  travando   pelo valor ta Boa   \n",
            "\n",
            "Original: Vendedor confiável, produto ok e entrega antes do prazo.\n",
            "Changed:  Vendedor confiável  produto ok e entrega antes do prazo \n",
            "\n",
            "Original: GOSTARIA DE SABER O QUE HOUVE, SEMPRE RECEBI E ESSA COMPRA AGORA ME DECPCIONOU\n",
            "Changed:  GOSTARIA DE SABER O QUE HOUVE  SEMPRE RECEBI E ESSA COMPRA AGORA ME DECPCIONOU\n",
            "\n",
            "Original: A compra foi realizada facilmente.  A entrega foi efetuada muito antes do prazo dado.  O produto já começou a ser usado e até o presente,  sem problemas.\n",
            "Changed:  A compra foi realizada facilmente   A entrega foi efetuada muito antes do prazo dado   O produto já começou a ser usado e até o presente   sem problemas \n",
            "\n"
          ]
        }
      ],
      "source": [
        "def re_special_chars(text_list):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text_series: list object with text content to be prepared [type: list]\n",
        "    \"\"\"\n",
        "\n",
        "    return [re.sub('\\W', ' ', r) for r in text_list]\n",
        "\n",
        "reviews_special_chars = re_special_chars(reviews_negation)\n",
        "df_comments['re_special_chars'] = reviews_special_chars\n",
        "\n",
        "print_diff(reviews_negation, reviews_special_chars, limit=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPuqhOJz2e2k"
      },
      "source": [
        "##### whitespaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZcyCaL02e2l",
        "outputId": "63dc9094-01f7-4dd4-dbd1-97e6dd47d899"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: Recebi bem antes do prazo estipulado \n",
            "Changed:  Recebi bem antes do prazo estipulado\n",
            "\n",
            "Original: aparelho eficiente  no site a marca do aparelho esta impresso como  numero desinfector e ao chegar esta com outro nome   atualizar com a marca correta uma vez que é o mesmo aparelho\n",
            "Changed:  aparelho eficiente no site a marca do aparelho esta impresso como numero desinfector e ao chegar esta com outro nome atualizar com a marca correta uma vez que é o mesmo aparelho\n",
            "\n",
            "Original: Mas um pouco  travando   pelo valor ta Boa   \n",
            "Changed:  Mas um pouco travando pelo valor ta Boa\n",
            "\n",
            "Original: Vendedor confiável  produto ok e entrega antes do prazo \n",
            "Changed:  Vendedor confiável produto ok e entrega antes do prazo\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def re_whitespaces(text_list):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text_series: list object with text content to be prepared [type: list]\n",
        "    \"\"\"\n",
        "\n",
        "    # Applying regex\n",
        "    white_spaces = [re.sub('\\s+', ' ', r) for r in text_list]\n",
        "    white_spaces_end = [re.sub('[ \\t]+$', '', r) for r in white_spaces]\n",
        "    return white_spaces_end\n",
        "\n",
        "reviews_whitespaces = re_whitespaces(reviews_special_chars)\n",
        "df_comments['re_whitespaces'] = reviews_whitespaces\n",
        "\n",
        "# Verifying results\n",
        "print_diff(reviews_special_chars, reviews_whitespaces)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-3O9Vxr2e2l"
      },
      "source": [
        "##### stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbgVnPFy2e2l",
        "outputId": "33ad18ce-10e7-4c27-fb53-78813e8a8c13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total portuguese stopwords in the nltk.corpous module: 207\n",
            "['a', 'à', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\darth\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Examples of some portuguese stopwords\n",
        "pt_stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "print(f'Total portuguese stopwords in the nltk.corpous module: {len(pt_stopwords)}')\n",
        "print(pt_stopwords[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxzScKdF2e2m",
        "outputId": "93357c3f-fb3f-40c6-c8ea-99a0f96f6ee6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: Recebi bem antes do prazo estipulado\n",
            "Changed:  recebi bem antes prazo estipulado\n",
            "\n",
            "Original: Parabéns lojas lannister adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa\n",
            "Changed:  parabéns lojas lannister adorei comprar internet seguro prático parabéns todos feliz páscoa\n",
            "\n",
            "Original: aparelho eficiente no site a marca do aparelho esta impresso como numero desinfector e ao chegar esta com outro nome atualizar com a marca correta uma vez que é o mesmo aparelho\n",
            "Changed:  aparelho eficiente site marca aparelho impresso numero desinfector chegar outro nome atualizar marca correta vez aparelho\n",
            "\n",
            "Original: Mas um pouco travando pelo valor ta Boa\n",
            "Changed:  pouco travando valor ta boa\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Defining a function to remove the stopwords and to lower the comments\n",
        "def stopwords_removal(text, cached_stopwords=nltk.corpus.stopwords.words('portuguese')):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text: list object where the stopwords will be removed [type: list]\n",
        "    cached_stopwords: stopwords to be applied on the process [type: list, default: stopwords.words('portuguese')]\n",
        "    \"\"\"\n",
        "\n",
        "    return [c.lower() for c in text.split() if c.lower() not in cached_stopwords]\n",
        "\n",
        "reviews_stopwords = [' '.join(stopwords_removal(review)) for review in reviews_whitespaces]\n",
        "df_comments['stopwords_removed'] = reviews_stopwords\n",
        "\n",
        "print_diff(reviews_whitespaces, reviews_stopwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2gBO7_F2e2m"
      },
      "source": [
        "##### stemming\n",
        "\n",
        "Stemming is a text normalization process used in Natural Language Processing (NLP) to reduce words to their root or base form. The goal is to group together different forms of a word so they can be analyzed as a single item. For example, the words \"running\", \"runner\", and \"ran\" can all be reduced to the root word \"run\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ozVKz0U2e2n",
        "outputId": "0d8f2d6b-dff9-4a74-e449-d4c8e2a6c314"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package rslp to\n",
            "[nltk_data]     C:\\Users\\darth\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download rslp\n",
        "nltk.download('rslp')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65_Dj5fr2e2n",
        "outputId": "d0510dc3-3bfe-4372-ba27-195efbfc0334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: recebi bem antes prazo estipulado\n",
            "Changed:  receb bem ant praz estipul\n",
            "\n",
            "Original: parabéns lojas lannister adorei comprar internet seguro prático parabéns todos feliz páscoa\n",
            "Changed:  parabém loj lannist ador compr internet segur prát parabém tod feliz pásco\n",
            "\n",
            "Original: aparelho eficiente site marca aparelho impresso numero desinfector chegar outro nome atualizar marca correta vez aparelho\n",
            "Changed:  aparelh efici sit marc aparelh impress numer desinfec cheg outr nom atual marc corret vez aparelh\n",
            "\n",
            "Original: pouco travando valor ta boa\n",
            "Changed:  pouc trav val ta boa\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Defining a function to remove the stopwords and to lower the comments\n",
        "def stemming_process(text, stemmer=nltk.stem.RSLPStemmer()):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ----------\n",
        "    text: list object where the stopwords will be removed [type: list]\n",
        "    stemmer: type of stemmer to be applied [type: class, default: RSLPStemmer()]\n",
        "    \"\"\"\n",
        "\n",
        "    return [stemmer.stem(c) for c in text.split()]\n",
        "\n",
        "# Applying stemming and looking at some examples\n",
        "reviews_stemmer = [' '.join(stemming_process(review)) for review in reviews_stopwords]\n",
        "df_comments['stemming'] = reviews_stemmer\n",
        "\n",
        "print_diff(reviews_stopwords, reviews_stemmer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bAqKArZC2e2p"
      },
      "outputs": [],
      "source": [
        "reviews_final = reviews_stemmer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5BN5mhvAICD"
      },
      "source": [
        "#### tokenization and pad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnpp2e-e_9Ue",
        "outputId": "ae425ff4-6d07-45b2-add4-b55a695434bc"
      },
      "outputs": [],
      "source": [
        "# Tokenization and padding\n",
        "# tokenizer = Tokenizer()\n",
        "# tokenizer.fit_on_texts(reviews_final)\n",
        "\n",
        "# reviews_sequences = tokenizer.texts_to_sequences(reviews_final)\n",
        "\n",
        "# max_length = max(len(seq) for seq in reviews_sequences)\n",
        "# reviews_padded = pad_sequences(reviews_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# reviews_padded[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDTJDqb52e2p"
      },
      "source": [
        "# Sentiment Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlTmgJNv2e2q"
      },
      "source": [
        "## Deep Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZSlwHMp2e2r"
      },
      "source": [
        "Dive data into train, validation and test (80%, 10%, 10%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"neuralmind/bert-base-portuguese-cased\"  # or \"microsoft/mdeberta-v3-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name, \n",
        "    num_labels=2,  # binary classification\n",
        ")\n",
        "num_epochs = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        # Tokenize the text\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, num_epochs, train_loader, val_loader, device, patience=3, save_path='transformers_weights'):\n",
        "    import os\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "    \n",
        "    # Number of training steps\n",
        "    num_training_steps = num_epochs * len(train_loader)\n",
        "    \n",
        "    # Create scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "    \n",
        "    # Store metrics\n",
        "    best_val_accuracy = 0.0\n",
        "    epochs_without_improvement = 0\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "        \n",
        "        # Training\n",
        "        model.train()\n",
        "        epoch_train_loss = 0\n",
        "        epoch_train_correct = 0\n",
        "        epoch_train_total = 0\n",
        "\n",
        "        for batch in tqdm(train_loader):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            \n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "            \n",
        "            loss = outputs.loss\n",
        "            epoch_train_loss += loss.item()\n",
        "            \n",
        "            # Calculate training accuracy\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            epoch_train_correct += (preds == labels).sum().item()\n",
        "            epoch_train_total += labels.size(0)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            \n",
        "            # Clip gradients\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            \n",
        "            # Update weights\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "        \n",
        "        # Calculate training metrics\n",
        "        avg_train_loss = epoch_train_loss / len(train_loader)\n",
        "        train_accuracy = epoch_train_correct / epoch_train_total\n",
        "        train_losses.append(avg_train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        print(f'Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.4f}')\n",
        "        \n",
        "        # Validation\n",
        "        model.eval()\n",
        "        epoch_val_loss = 0\n",
        "        epoch_val_correct = 0\n",
        "        epoch_val_total = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "                \n",
        "                outputs = model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    labels=labels\n",
        "                )\n",
        "\n",
        "                epoch_val_loss += outputs.loss.item()\n",
        "                preds = torch.argmax(outputs.logits, dim=1)\n",
        "                epoch_val_correct += (preds == labels).sum().item()\n",
        "                epoch_val_total += labels.size(0)\n",
        "        \n",
        "        # Calculate validation metrics\n",
        "        avg_val_loss = epoch_val_loss / len(val_loader)\n",
        "        val_accuracy = epoch_val_correct / epoch_val_total\n",
        "        val_losses.append(avg_val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "        print(f'Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.4f}')\n",
        "\n",
        "        model_save_path = os.path.join(save_path, f'model_epoch_{epoch}.pt') \n",
        "        torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "        # Early stopping logic\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            epochs_without_improvement = 0\n",
        "\n",
        "            model_save_path = os.path.join(save_path, f'best_model{epoch}.pt') \n",
        "            torch.save(model.state_dict(), model_save_path)\n",
        "            print(f\"New best model saved (Accuracy: {best_val_accuracy:.4f})\")\n",
        "\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            print(f\"No improvement for {epochs_without_improvement}/{patience} epochs\")\n",
        "            \n",
        "            if epochs_without_improvement >= patience:\n",
        "                print(f\"Early stopping triggered (no improvement for {patience} epochs)\")\n",
        "                break\n",
        "    \n",
        "    print(f\"\\nTraining complete. Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
        "    \n",
        "    metrics = {\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'val_accuracies': val_accuracies,\n",
        "        'best_val_accuracy': best_val_accuracy\n",
        "    }\n",
        "\n",
        "    return model, metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Prepare data and train\n",
        "# Assuming df_comments is your DataFrame with 'comment' and binary 'score' columns\n",
        "X = reviews_final\n",
        "y = y.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=seed)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ReviewDataset(X_train, y_train, tokenizer)\n",
        "val_dataset = ReviewDataset(X_val, y_val, tokenizer)\n",
        "test_dataset = ReviewDataset(X_test, y_test, tokenizer)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2049, 257, 257)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_loader), len(val_loader), len(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "model = model.to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/2049 [00:05<3:13:30,  5.67s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[36], line 60\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, num_epochs, train_loader, val_loader, device, patience, save_path)\u001b[0m\n\u001b[0;32m     57\u001b[0m epoch_train_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Clip gradients\u001b[39;00m\n\u001b[0;32m     63\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
            "File \u001b[1;32md:\\Code\\Data Science\\Projects\\brazilian-e-commerce-nlp-deep-learning\\.venv\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Code\\Data Science\\Projects\\brazilian-e-commerce-nlp-deep-learning\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Code\\Data Science\\Projects\\brazilian-e-commerce-nlp-deep-learning\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "train_model(model, num_epochs, train_loader, val_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzTEq2ws2e22"
      },
      "source": [
        "## Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "qY32MWj82e23"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(y_true, y_pred):\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.2f}\")\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Satisfied', 'Satisfied'], yticklabels=['Not Satisfied', 'Satisfied'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "def display_predictions(df, y_true, y_pred, n=5):\n",
        "    df['true_label'] = y_true\n",
        "    df['predicted_label'] = y_pred\n",
        "    correct = df[df['true_label'] == df['predicted_label']].sample(n)\n",
        "    incorrect = df[df['true_label'] != df['predicted_label']].sample(n)\n",
        "\n",
        "    print(\"Correct Predictions:\")\n",
        "    print(correct[['comment', 'true_label', 'predicted_label']])\n",
        "    print(\"\\nIncorrect Predictions:\")\n",
        "    print(incorrect[['comment', 'true_label', 'predicted_label']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "ir39dCOF2e23",
        "outputId": "4a283f11-d00a-43d5-80b1-9889df16019c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.80      0.82      1398\n",
            "           1       0.90      0.93      0.91      2700\n",
            "\n",
            "    accuracy                           0.88      4098\n",
            "   macro avg       0.87      0.86      0.87      4098\n",
            "weighted avg       0.88      0.88      0.88      4098\n",
            "\n",
            "Accuracy: 0.88\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "X_array_original = np.array(df_comments['comment'])\n",
        "\n",
        "y_pred = best_lstm_model.predict(X_test)\n",
        "y_pred_binary = np.where(y_pred >= 0.5, 1, 0)\n",
        "\n",
        "# Visualize examples\n",
        "def get_correct_and_incorrect(X_test: np.array, y_test: pd.Series, y_pred: np.array, n=10):\n",
        "    df_test = pd.DataFrame(X_test).iloc[y_test.index]\n",
        "    df_test['true_label'] = y_test.values\n",
        "    df_test['predicted_label'] = y_pred\n",
        "    df_test.columns = ['comment' if i == 0 else col for i, col in enumerate(df_test.columns)]\n",
        "\n",
        "    correct = df_test[df_test['true_label'] == df_test['predicted_label']].sample(n)\n",
        "    incorrect = df_test[df_test['true_label'] != df_test['predicted_label']].sample(n)\n",
        "\n",
        "    return correct, incorrect\n",
        "\n",
        "correct, incorrect = get_correct_and_incorrect(X_array_original, y_test, y_pred_binary)\n",
        "\n",
        "evaluate_model(y_test, y_pred_binary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "Mw5guExz2e24",
        "outputId": "82b21e4d-7a68-4df1-d1f2-0a3abf283be2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct examples:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>true_label</th>\n",
              "      <th>predicted_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28131</th>\n",
              "      <td>Muito bom</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35628</th>\n",
              "      <td>Já faz mais de 1 mês que comprei, e nada de en...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31916</th>\n",
              "      <td>Bom</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30046</th>\n",
              "      <td>Entrega nao foi feita , pedsimo atendimento . ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36677</th>\n",
              "      <td>Gostei muito parabéns</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32990</th>\n",
              "      <td>Relógios Casio são os melhores, principalmente...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18308</th>\n",
              "      <td>olha eu comprei dois produtos mas so foi entre...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4879</th>\n",
              "      <td>Comprei e eles não tinham o produto.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24595</th>\n",
              "      <td>Ótima lindo..</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3095</th>\n",
              "      <td>excelente</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 comment  true_label  \\\n",
              "28131                                          Muito bom           1   \n",
              "35628  Já faz mais de 1 mês que comprei, e nada de en...           0   \n",
              "31916                                                Bom           1   \n",
              "30046  Entrega nao foi feita , pedsimo atendimento . ...           0   \n",
              "36677                              Gostei muito parabéns           1   \n",
              "32990  Relógios Casio são os melhores, principalmente...           1   \n",
              "18308  olha eu comprei dois produtos mas so foi entre...           0   \n",
              "4879               Comprei e eles não tinham o produto.            0   \n",
              "24595                                      Ótima lindo..           1   \n",
              "3095                                           excelente           1   \n",
              "\n",
              "       predicted_label  \n",
              "28131                1  \n",
              "35628                0  \n",
              "31916                1  \n",
              "30046                0  \n",
              "36677                1  \n",
              "32990                1  \n",
              "18308                0  \n",
              "4879                 0  \n",
              "24595                1  \n",
              "3095                 1  "
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Correct examples:\")\n",
        "correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "WOlWFqNw2e24",
        "outputId": "1edb448c-fbd5-419b-bcfe-0d89a1726594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Incorrect examples:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>true_label</th>\n",
              "      <th>predicted_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3248</th>\n",
              "      <td>Só que na descrição do produto, consta q vem c...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36316</th>\n",
              "      <td>Gostei muito da mercadoria e gostaria de fazer...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39138</th>\n",
              "      <td>Nao entrega o pedido no prazo certo</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14857</th>\n",
              "      <td>Como das outras compras não tive problemas.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23198</th>\n",
              "      <td>Recebi tudo amtes do prazo o teclaclado é top,...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34638</th>\n",
              "      <td>demorou muito o produto ser entregue eu pensav...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22756</th>\n",
              "      <td>Na descrição do produto a base do pendente era...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1147</th>\n",
              "      <td>Arranhador veio com lascas na base por conta d...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4592</th>\n",
              "      <td>Produto idêntico ao anunciado. Não recebi no p...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12564</th>\n",
              "      <td>Ótima compra demoro um pouco para chegar mais ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 comment  true_label  \\\n",
              "3248   Só que na descrição do produto, consta q vem c...           1   \n",
              "36316  Gostei muito da mercadoria e gostaria de fazer...           1   \n",
              "39138               Nao entrega o pedido no prazo certo            0   \n",
              "14857        Como das outras compras não tive problemas.           1   \n",
              "23198  Recebi tudo amtes do prazo o teclaclado é top,...           1   \n",
              "34638  demorou muito o produto ser entregue eu pensav...           1   \n",
              "22756  Na descrição do produto a base do pendente era...           1   \n",
              "1147   Arranhador veio com lascas na base por conta d...           0   \n",
              "4592   Produto idêntico ao anunciado. Não recebi no p...           1   \n",
              "12564  Ótima compra demoro um pouco para chegar mais ...           0   \n",
              "\n",
              "       predicted_label  \n",
              "3248                 0  \n",
              "36316                0  \n",
              "39138                1  \n",
              "14857                0  \n",
              "23198                0  \n",
              "34638                0  \n",
              "22756                0  \n",
              "1147                 1  \n",
              "4592                 0  \n",
              "12564                1  "
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Incorrect examples:\")\n",
        "incorrect\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-nXvQwz2e25"
      },
      "source": [
        "## Dense model with Regex Transformers + TF-IDF Vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tEsKkX32e25"
      },
      "source": [
        "### Feature Extraction\n",
        "\n",
        "After the RegEx, stopwords removal and stemming application, we can use Bag of Words, TF-IDF and Word2Vec to get more meaning. To make our analysis easier, let's define a function that receives a text and a vectorizer object and applies the feature extraction on the respective text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyOoN_BF2e25"
      },
      "source": [
        "#### CountVectorizer\n",
        "\n",
        "Count vectorization is a technique in NLP that converts text documents into a matrix of token counts. Tokens can be words, characters, or n-grams. Each token represents a column in the matrix, and the resulting vector for each document has counts for each token.\n",
        "\n",
        "On the Bag of Words approach, we create a dictionary vocabulary with all the unique words and, for each word in each comment/text string, we index the words into a vector that represents the occurrence (1) or not (0) of each word. This is a way for transforming a text into a frequency vector considering a literal bag of words (dictionary vocabulary).\n",
        "\n",
        "Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVt67_3Y2e26",
        "outputId": "231f1eb0-e93a-4134-ab6d-5840e1866f3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'this': 8,\n",
              " 'is': 3,\n",
              " 'the': 6,\n",
              " 'first': 2,\n",
              " 'document': 1,\n",
              " 'second': 5,\n",
              " 'and': 0,\n",
              " 'third': 7,\n",
              " 'one': 4}"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus = [\n",
        "    'This is the first document',\n",
        "    'This document is the second document',\n",
        "    'and this is the third one',\n",
        "    'is this the first document'\n",
        "]\n",
        "\n",
        "vec = CountVectorizer().fit(corpus)\n",
        "vec.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfgX6YcZ2e26",
        "outputId": "f0d6d1fc-5b84-4e28-c7ed-3b096f417761"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
              "       [0, 2, 0, 1, 0, 1, 1, 0, 1],\n",
              "       [1, 0, 0, 1, 1, 0, 1, 1, 1],\n",
              "       [0, 1, 1, 1, 0, 0, 1, 0, 1]])"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vec.transform(corpus).toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1usMedh2e27"
      },
      "source": [
        "#### TF-IDF\n",
        "\n",
        "With the Bag of Words approach, each word has the same weight, which may not be true all the time, especially for those words with a very low frequency in the corpus. So, the TF-IDF (Term Frequency and Inverse Document Frequency) approach can be used with the scikit-learn library following the formulas:\n",
        "\n",
        "$$\n",
        "TF = \\frac{\\text{Frequency of a word in the document}}{\\text{Total words in the document}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "IDF = \\log\\left(\\frac{\\text{Total number of documents}}{\\text{Number of documents containing the word}}\\right)\n",
        "$$\n",
        "\n",
        "The purpose of using tf-idf instead of simply counting the frequency of a token in a document is to reduce the influence of tokens that appear very frequently in a given collection of documents. These tokens are less informative than those appearing in only a small fraction of the corpus. Scaling down the impact of these frequently occurring tokens helps improve text-based machine-learning models’ accuracy.\n",
        "\n",
        "Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqLh6YU_2e27",
        "outputId": "ed8c12cd-949c-474c-a4e5-6049344ddc5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
              "        0.        , 0.38408524, 0.        , 0.38408524],\n",
              "       [0.        , 0.6876236 , 0.        , 0.28108867, 0.        ,\n",
              "        0.53864762, 0.28108867, 0.        , 0.28108867],\n",
              "       [0.51184851, 0.        , 0.        , 0.26710379, 0.51184851,\n",
              "        0.        , 0.26710379, 0.51184851, 0.26710379],\n",
              "       [0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
              "        0.        , 0.38408524, 0.        , 0.38408524]])"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorized = vec.transform(corpus).toarray()\n",
        "tfid = TfidfTransformer().fit(vectorized)\n",
        "\n",
        "tfid.transform(vectorized).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "Sc9MiVU_2e27"
      },
      "outputs": [],
      "source": [
        "# [TEXT PREP] Class to apply multiple RegEx functions on a dict\n",
        "class ApplyRegex(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, regex_transformers):\n",
        "        self.regex_transformers = regex_transformers\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        # Applying all regex functions in the regex_transformers dictionary\n",
        "        for regex_name, regex_function in self.regex_transformers.items():\n",
        "            X = regex_function(X)\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "# [TEXT PREP] Class to remove stopwords\n",
        "class StopWordsRemoval(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, text_stopwords):\n",
        "        self.text_stopwords = text_stopwords\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return [' '.join(stopwords_removal(comment, self.text_stopwords)) for comment in X]\n",
        "\n",
        "\n",
        "# [TEXT PREP] Class to apply stemming\n",
        "class StemmingProcess(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, stemmer):\n",
        "        self.stemmer = stemmer\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return [' '.join(stemming_process(comment, self.stemmer)) for comment in X]\n",
        "\n",
        "\n",
        "# [TEXT PREP] Class to extract features (vocab / bag of words / TF-IDF)\n",
        "class TextFeatureExtraction(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, vectorizer, train=True):\n",
        "        self.vectorizer = vectorizer\n",
        "        self.train = train\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        if self.train:\n",
        "            return self.vectorizer.fit_transform(X).toarray()\n",
        "        else:\n",
        "            return self.vectorizer.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "WWuSW3LX2e28"
      },
      "outputs": [],
      "source": [
        "# Defining regex transformers to be applied\n",
        "regex_transformers = {\n",
        "    'break_line': re_breakline,\n",
        "    'hiperlinks': re_hiperlinks,\n",
        "    'dates': re_dates,\n",
        "    'money': re_money,\n",
        "    'numbers': re_numbers,\n",
        "    'negation': re_negation,\n",
        "    'special_chars': re_special_chars,\n",
        "    'whitespaces': re_whitespaces\n",
        "}\n",
        "\n",
        "# Defining the vectorizer to extract features from text\n",
        "vectorizer = TfidfVectorizer(max_features=300, min_df=7, max_df=0.8, stop_words=pt_stopwords)\n",
        "\n",
        "# Building the Pipeline\n",
        "text_pipeline = Pipeline([\n",
        "    ('regex', ApplyRegex(regex_transformers)),\n",
        "    ('stopwords', StopWordsRemoval(nltk.corpus.stopwords.words('portuguese'))),\n",
        "    ('stemming', StemmingProcess(nltk.stem.RSLPStemmer())),\n",
        "    ('text_features', TextFeatureExtraction(vectorizer))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4qCk9Q_2e28"
      },
      "source": [
        "* max_features=300: indicates that the matrix will be created using the 300 most common words from the corpus\n",
        "* max_df=0.8: indicates that we will use only words with at least 80% frequency in the corpus\n",
        "* min_df=7: indicates that we will use only words that occurs in at least 7 text strings in the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "gUUOoFpy2e29"
      },
      "outputs": [],
      "source": [
        "X = df_comments['comment']\n",
        "\n",
        "X_transformed = text_pipeline.fit_transform(reviews_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "0an69owE2e29"
      },
      "outputs": [],
      "source": [
        "X_train_trans, X_val_trans, X_test_trans, y_train_trans, y_val_trans, y_test_trans = train_val_test_split(X_transformed, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvP0jDeT2e29",
        "outputId": "00099d29-4103-4a6a-9cf3-eb53cde9dfb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.43824671,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.32527411, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.25943248, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.27427872, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.65831002, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.29037051,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.2047326 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ])"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_trans[500]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjpl-lV12e3B"
      },
      "source": [
        "## Test with sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "NHtxNJz82e3B"
      },
      "outputs": [],
      "source": [
        "def test_new_sentence_lstm(new_sentence, model, tokenizer=tokenizer, max_sequence_length=max_length):\n",
        "    regex_transformers = {\n",
        "        'break_line': re_breakline,\n",
        "        'hiperlinks': re_hiperlinks,\n",
        "        'dates': re_dates,\n",
        "        'money': re_money,\n",
        "        'numbers': re_numbers,\n",
        "        'negation': re_negation,\n",
        "        'special_chars': re_special_chars,\n",
        "        'whitespaces': re_whitespaces\n",
        "    }\n",
        "\n",
        "\n",
        "    # Pre-process\n",
        "    regex = ApplyRegex(regex_transformers)\n",
        "    sentence_processed = regex.transform([new_sentence])\n",
        "    sentence_processed = [' '.join(stopwords_removal(review)) for review in sentence_processed]\n",
        "    sentence_processed = [' '.join(stemming_process(review)) for review in sentence_processed]\n",
        "\n",
        "    print(sentence_processed)\n",
        "\n",
        "    # Tokenizer and padding e aplicando padding\n",
        "    tokenized_sentence = tokenizer.texts_to_sequences(sentence_processed)\n",
        "    padded_sentence = pad_sequences(tokenized_sentence, maxlen=max_sequence_length, padding=\"post\")\n",
        "    print(padded_sentence)\n",
        "\n",
        "    # Result\n",
        "    prediction = model.predict(padded_sentence)\n",
        "    print(prediction)\n",
        "\n",
        "    review = \"positive\" if prediction >= 0.5 else \"negative\"\n",
        "    print(f\"The sentence represents a {review} review!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BHxy-qI2e3C",
        "outputId": "9ddc40ed-40df-49ed-bd16-9a657e30c4c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['compr gift card aind esper cheg produt digit tod sit mand instant vulg mai amér latin simples neg conseg entreg simpl códig mail neg recom serviç péss']\n",
            "[[   5 3568   19   27    7    1  943   38   35  114 3512  204 1199  411\n",
            "     2  832    3  322  487  232    2   11  182  126    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "[[0.04152721]]\n",
            "The sentence represents a negative review!\n"
          ]
        }
      ],
      "source": [
        "new_sentence = 'Comprei um gift card e ainda estou esperando chegar, é um produto digital, todos os sites mandam no mesmo instante, \\\n",
        "e o vulgo \"maior da América Latina\" simplesmente não consegue entregar um simples código no e-mail. Não recomendo, serviço péssimo.'\n",
        "test_new_sentence_lstm(new_sentence, best_lstm_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTA1Ac542e3C",
        "outputId": "b35fd240-cf9d-4188-bef2-5841f72cd028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['estud institu selecion receb benefíci pae semestr numer numer receb pag benefíci mê pass atras mê aind neg receb coleg selecion benefíci fal receb numer numer tod poi mê pass receb numer mê numer mand mail busc ajud respond esper numer dia utel lig mand retorn segund feir numer novembr hoj lig descobr folh pag fech receb pag jan solic benefíci expliq solicit poi através mant desp estud almoç transport benefíci neg consegu continu estud univers agor esper jan cont err institu pod corr risc neg consegu assist aul cont falt transport']\n",
            "[[ 489    8   53  964  871  377 4841   95   39  721  571 3132 1765 3504\n",
            "   240  377    2  252  231 1765 1422   52   27  964  216   79 4086   72\n",
            "   431  427    2  252 1134 6632  216   45  240]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "[[0.27401313]]\n",
            "The sentence represents a negative review!\n"
          ]
        }
      ],
      "source": [
        "new_sentence='Sou estudante da instituição e fui selecionada para receber o benefício PAES no semestre 2024.1, \\\n",
        "recebi o pagamento do benefício do mês passado com atraso e este mês ainda não recebi. Colegas que também foram selecionados pelo benefício,\\\n",
        "falaram que já receberam 1.200 ao todo, pois no mês passado receberam 800 e este mês, 400. Mandei e-mails em busca de uma ajuda e me \\\n",
        "responderam para esperar os 10 dias uteis, liguei e me mandaram retornar na segunda-feira, 18 de novembro (hoje) e ao ligar, descobri que a \\\n",
        "folha de pagamento fechou e só receberei o meu pagamento em janeiro. Ao solicitar esse benefício, expliquei que estava solicitando pois através \\\n",
        "dele, eu manteria as minhas despesas como estudante (almoço e transporte) e sem este benefício, eu não conseguiria continuar estudando na universidade.\\\n",
        "Agora terei que esperar até janeiro por conta de um erro da instituição, podendo correr o risco de não conseguir assistir as aulas por conta da falta de transporte.'\n",
        "test_new_sentence_lstm(new_sentence, best_lstm_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfgJyy1N2e3D",
        "outputId": "0c518865-a3e8-43a9-e000-b2bf8b8de5e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['sit post comunic prim respost verific document mand edit diz pod reenvi document cas neg compat inscr porém sit consult neg dão opç reenvi soment consult document envi anteri']\n",
            "[[  35  348  428  130  120  464 1249  114  145   72  948 1249  109    2\n",
            "   598   44   35 1289    2  834  546  948  122 1289 1249   56  642    0\n",
            "     0    0    0    0    0    0    0    0    0]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "[[0.18486482]]\n",
            "The sentence represents a negative review!\n"
          ]
        }
      ],
      "source": [
        "new_sentence='O SITE POSTOU UM COMUNICADO COM A PRIMEIRA RESPOSTA DA VERIFICAÇÃO DOS DOCUMENTOS E MANDOU UM EDITAL DIZENDO QUE EU PODERIA REENVIAR OS DOCUMENTOS CASO NÃO TIVESSE COMPATÍVEL COM A INSCRIÇÃO. PORÉM, NO SITE DE CONSULTA, NÃO ME DÃO A OPÇÃO DE REENVIAR, MAS SOMENTE A DE CONSULTAR O DOCUMENTOS QUE JÁ ENVIEI ANTERIORMENTE.'\n",
        "test_new_sentence_lstm(new_sentence, best_lstm_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms9XhS9p2e3D",
        "outputId": "b9777bcf-27ce-44a1-97cf-1504a9aaa955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['excel produt pessoal parab legal gost volt']\n",
            "[[ 23   1 688 298 430  17 123   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "[[0.97859794]]\n",
            "The sentence represents a positive review!\n"
          ]
        }
      ],
      "source": [
        "new_sentence='Excelente produto pessoal, parabens, legal, gostei, voltarei!'\n",
        "test_new_sentence_lstm(new_sentence, best_lstm_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r86jYtCR2e3D",
        "outputId": "9c804fc1-4fd9-4f3b-f08d-a63eda5f9ec2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['neg palavr descrev quã espec mim sei caix mens dev chei poi pesso quer tod gost relembr tod car sint quã grat ter vid hoj quer desej feliz aniversári dia muit celebr abraç apert sorris sincer lad pesso ama esper pod celebr muit outr ano contig parabém dia']\n",
            "[[ 191  101  410   75  814   39  358   61   38   17   38  198  885  417\n",
            "    69 1107  134   61  230  288  933   21  179  927  930 6649 2251  671\n",
            "   358 3362   27   72  179   32  308   48   21]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "[[0.7218724]]\n",
            "The sentence represents a positive review!\n"
          ]
        }
      ],
      "source": [
        "new_sentence='Não tenho palavras para descrever o quão especial você é para mim. Sei que sua caixa de mensagens deve estar cheia, pois você é uma pessoa muito querida por todos. Mas gostaria de te relembrar todo o carinho que sinto por você e quão grato eu sou por te ter na minha vida.\\\n",
        "Hoje, quero lhe desejar o mais feliz dos aniversários. Que esse dia seja de muita celebração, abraços apertados e sorrisos sinceros ao lado das pessoas que você mais ama. Espero poder celebrar muitos outros anos contigo.\\\n",
        "Parabéns pelo seu dia.'\n",
        "test_new_sentence_lstm(new_sentence, best_lstm_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
